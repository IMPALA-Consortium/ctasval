---
title: "ctas validation"
author:
  - name: Pekka Tiikkainen
    corresponding: true
    email: pekka.tiikkainen@bayer.com
    affiliations:
      - Bayer
  - name: Frederik Collin
    corresponding: false
    email: frederik_raphael.collin@boehringer-ingelheim.com
    affiliations:
      - Boehringer Ingelheim  
  - name: Bj√∂rn Koneswarakantha
    orcid: 0000-0003-4585-7799
    corresponding: false
    email: bjoern.koneswarakantha@roche.com
    affiliations:
      - Roche
output: rmarkdown::html_vignette
toc: true
bibliography: ctas.bib
csl: elsevier-vancouver.csl # https://github.com/citation-style-language/styles/blob/master/elsevier-vancouver.csl
editor_options: 
  chunk_output_type: console
---

```{r include = FALSE}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(purrr))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(tibble))
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(patchwork))
suppressPackageStartupMessages(library(ctasval))
suppressPackageStartupMessages(library(gt))

here::i_am("inst/pub/ctasvalidation.qmd")

# Define the custom theme for scientific publications
theme_ctas <- function() theme_bw(base_size = 9)
```


# Enhancing Data Quality in Clinical Trials: Cross-company Validation of the Open-source Clinical Trial Anomaly Spotter (CTAS)


## Abstract


### Background

Current ICH guidelines, e.g. ICH E6 (R3), advocate a risk-based statistical review of clinical trial data to identify anomalies. The open source R package, clinical trial anomaly spotter (CTAS) has been developed by Bayer and the Intercompany Quality Analytics (IMPALA) consortium, helps detect inconsistencies in subject time series data at both site and subject levels, facilitating timely intervention.

### Methods

CTAS analyzes time series of equal length. Each subject-level time series is summarized as six optional scalars mean, standard deviation, range, relative unique value count, autocorrelation and local outlier factor. To detect site-level anomalies sites can be scored using 3 different scoring methods. The performance of the CTAS algorithm was tested using simulations, artificially introducing site anomalies of varying types and degrees into clinical trial data sets.

### Results

We find that CTAS can reliably detect site anomalies depending on the degree of the anomaly introduced. Less complex anomalies such as mean were easier to detect than complex outlier such as local outlier factor. The three scoring methods differed in their ability to detect anomalous sites with a small number of patients and their false positive rates.

### Conclusions

CTAS is a valuable tool for timely detection of outliers in clinical data, suitable for integration into risk-based strategies. Choosing the appropriate site anomaly scoring method is crucial for handling sites with fewer subjects effectively.

# Keywords (required section)

RBQM, SDM, time series, anomaly, clinical trial, outlier


# Introduction (required section)

Most clinical trial data consist of repeated measurements taken of the same patients over the duration of the trial. The integrity of these data points is mostly challenged by systemic errors introduced at site level which can have root causes such as: misinterpretation of the protocol, miscalibration of laboratory tests or devices, insufficient staff training and many more. These errors will affect a larger portion of patients enrolled at the site and should be statistically detectable as site-level anomalies given that sufficient compliant data has been collected within the current trial data set. Classical risk mitigation strategies consist of a combination of monitoring activities such as source data verification (SDV) and source data review (SDR), programmed data management edit checks and medical data review.

Ensuring the high quality of data is a major responsibility of the clinical trial sponsor. Current ICH guidelines, e.g. ICH E6 (R3), recommended a risk-based statistical approach to monitor the completeness, expected range and variability of the clinical trial data @noauthor_ich_1997. So called central monitoring activities are part of the risk-based quality monitoring (RBQM) framework one of which is statistical data monitoring (SDM).

Subject-level data in clinical trial can be collected as categorical, ordinal or numerical data, as a single measurement or as a time series. Typically, all of these data types require different statistical tests. Consequently, statistical data monitoring tools execute a myriad of test @venet_statistical_2012, @kirkwood_application_2013, @trotta_detection_2019 and it has been shown that the application of such tools can improve data quality over time @de_viron_does_2024 Recently an RBQM open source solution focusing on the monitoring of site key risk indicators (KRI) has been published @wu_good_2024 but presently, no open source solution has been published aggregating central data monitoring methods into one tool.

In this paper, we present an evaluation of Clinical Trial Anomaly Spotter (CTAS) - an open-source R package for the identification of anomalous clinical trial time series. The package was developed originally by Bayer, and later co-developed by the Intercompany Quality Analytics (IMPALA) consortium. IMPALA has currently 19 industry members and promotes the use and development of analytics for GxP quality assurance @menard_cross-company_2021. CTAS fills the central statistical data monitoring gap of the current open source RBQM landscape. It has foremost been developed for the detection of anomalies in numerical time series data at site and subject level. CTAS strong focus on time series data ensures that only time series of the same length are being compared suppressing false positive signals.

Here we demonstrate the efficiency in detecting anomalous sites using simulations based on data from 15 clinical trials donated by three of the IMPALA member companies.

# Methods (required section)

## Algorithm

### Clinical Trial Time Series


In a clinical trial patient data is typically collected as repeated measures over time, tracking pivotal health measurements of all patients during the course of a trial. As patients can enter the trial at different times and thus the individual length of each time series depends on the time that has passed since enrollment. The number of data points collected depends on how often a meassurement was collected and may contain missing values when assessments have been skipped. The actual values measured may also dependend on scheduled treatments and assessment as well as on disease progression. All of these factors complicate active SDM of ongoing trials.
CTAS has been developed to only compare time series composed of the same time points. It will actively comb throught the data and find as many groups of timeseries of equal length that fullfill a set of parametrized minimum requirements. Detailed parameter descriptions can be found in the project's public code repository (see Supplementary Material). Alternatively, time series can also be defined manually including fixed sets of visits. CTAS expects measurements to be numerical, thus any categorical values need to be transformed to an appropriate numerical format. CTAS will then calculate a set of relevant aggregate features for each time series which can then be used to identify site and subject outliers.

#### Defining Time Series

In an ongoing study, some subjects might have only taken the first visits while some have already finished the study. This is the reason why more than one group of time series with various length per parameter should be defined. One group would include almost all planned time points and compares subjects which have largely finished the trial. Another shorter group includes only the first few visits to also include subjects which have only lately been enrolled. As illustrated in @fig-timeseries-def individual subject data points may also be missing. These time series groups can be manually defined or CTAS will start to iteratively look for suitable groups starting with the longest possible group and decrease the length if the number of eligable subjects can be increased by at least 20 percent. A time series group should have a minimum group size which can be set via a CTAS parameter, we currently recommend a minimum group size of 25 subjects.
Eligable subjects must also not exceed the maximum ratio of missing values, which is another CTAS parameter for which the recommendation is 30%. Traditionally, time series should have at least three data point, however some measurements will only be taken once possibly during screening. Therefore CTAS also allows time series of length one, altough not all subsequent time series features e.g. autocorrelation (see the following section) will be meaningfull.

#### Timeseries Features

Each time series is characterized by a set of time series features, which summarize all time series values into a single metric. These features are central to the algorithm as they are used to flag anomalous sites (see below). In addition, the features can be used to identify individual subjects with peculiar time series. Currently available time series features are listed in @tbl-features.

All feature types except LOF are context-free meaning that only measurements in the time series are needed to calculate them. LOF on the other hand is context-dependent as its value depends also on the other time series in the study.

For an illustration of features for a time series, please see @fig-timeseries-feats.

### Flagging Sites

Flagging sites with a systematic bias in their data collection is an important part of study monitoring. If identified early enough, the site can be offered further training if the site has had trouble in interpreting the study protocol. In the extreme case, if the bias is due to intentional misconduct, the site can be closed and excluded from analysis.

Sites are flagged based on the bias in their time series feature values versus other sites in the study. CTAS offers three options for flagging sites: Kolmogorov-Smirnov, mixed effects modelling and the simple average of the feature values.

#### Kolmogorov-Smirnov

The Kolmogorov-Smirnov (K-S) statistical test compares time series feature values of individual sites against the combined values from all other sites. This non-parametric test evaluates the null hypothesis that the feature values from a specific site and the feature values from all other sites are drawn from the same distribution @schroer_exact_1995.

The K-S test calculates the maximum difference between the empirical cumulative distribution functions (ECDFs) of the two samples, providing a D-statistic and a p-value for each comparison. The p-value indicates the significance of the difference between the distributions. A low p-value suggests that the feature values from the site are significantly different to those from other sites, potentially indicating an anomaly. The uncorrected p-value produced by the K-S test is further corrected with the FDR method to account for multiple testing @benjamini_controlling_1995.

@fig-site-flagging gives an example on how the method is used to identify a site with relatively few unique values per time series.

#### Mixed effects modelling

This approach allows us to account for both fixed and random effects in the data, providing a robust framework for detecting anomalies.

We fit a mixed effects model to the data, where the hierarchical structure of the data is taken into account by including random effects for different levels (i.e., sites nested within countries and regions). After fitting the model, we simulate the random effects to obtain estimates for each entity (sites, countries, and regions). For each entity, we calculate the median and standard deviation of the random effects. Additionally, the median and standard deviation are used to calculate a p-value for each entity's deviation from zero, providing a statistical measure of the significance of the abnomaly. Like in the K-S test, this raw p-value is further adjusted with the FDR method @benjamini_controlling_1995.

One significant advantage of using mixed effects models in this context is their ability to account for region-level and country-level demographic factors when scoring sites. By incorporating these higher-level random effects, the model can more accurately detect site-specific biases while controlling for broader demographic influences. This approach provides a comprehensive understanding of potential biases across different study sites, countries, and regions.

#### Average feature value

As a simple baseline model for anomaly detection, we also scored sites based on the average feature values of the subjects at each site. Then outlier were defined as being outside of the interquartile range multiplied by 1.5 @vinutha_detection_2018. This straightforward approach involves calculating the mean feature value for each site and using these averages to identify potential anomalies. It is included in order to have a benchmark to see if the more complex site flagging methods are able to outperform it. Note that the method does not produce a p-value but a binary outcome on whether the site is an outlier or not.

The primary advantage of this method is its simplicity and ease of understanding. It provides a clear and straightforward way to identify sites with unusual feature values. However, this approach does not take into account the size of the site. A site with only one subject who has an extreme feature value may get flagged, even though this could be due to chance alone and may not indicate a systematic issue with the site. Like the Kolmogorov-Smirnov approach, this method does not account for region and country-level demographic factors that might influence feature values.

### Identifying Anomalies in Individual Time Series

In addition to flagging sites, the results are valuable for identifying individual subjects with anomalous time series. Sites which exhibit no systematic bias might still contain individual anomalous subjects and time series. One way is to visually inspect similarity plots for subjects with few near neighbors. @fig-similarity-plot gives an example of this for an anomalous weight profile. Another approach is to compare time series features and review time series with extreme values for one or more of these. Please see @fig-sd-example for an example on this. Please note that outliers identified with the two approaches often correlate, e.g., subjects with unusually high standard deviations also tend to be outliers on the similarity plot.


## Validation

To evaluate CTAS performance for detecting sites with anomalous time series we selected data from two laboratory (Alanine Aminotransferase, Creatinine) and two vitals measurements (Systolic Blood Pressure, Weight) from a clinical trial data set and reassigned all patients to different sites creating a synthetic data set closely following actual trial outcomes and schedules but also removing all regional or country-specific signal. Further we removed data points from unscheduled visits and data from screening failures. In total, 15 completed studies were selected from 3 different IMPALA members in triplicates with comparable patient and site number.

For time series features calculated by CTAS we applied a specific transformation with a given degree to the measurements of three randomly added sites.

-   Average: Add the site mean multiplied by the anomaly degree to original values.
-   Standard Devaition: Add site mean multiplied with the anomaly degree to each observations and randomly apply a negative or positive fore-sign.
-   Range: Add one outlier data point per patient. The extremity of the outlier is based on the anomaly degree.
-   Unique Value Ratio: Replace a ratio of observations with the first observed value per patient. The ratio would be determined by the anomaly degree.
-   Autocorrelation: Add the preceeding value multiplied by the anomoly degree to each value.
-   Local outlier factor: Transform data for each patient by a randomly chosen non-normal distribution. The anomaly degree would determine the ratio of affected patients.

The anomalies introduced are visualized in @fig-anomalies based on a simulated sdtm test data set. @mancini_pharmaversesdtm_2025

Subsequently we tried to detect the three anomalous sites using different site scoring methods among the compliant sites in the study data set. We set the minimum time series length to one and required at least 25 patients per time series group with a maximum ratio of missing values of 30% per subject. For each site we used the highest CTAS score and employed a threshold of 1.3 if applicable. This was repeated a 100 times and true positive rate (TPR) and false positive rate (FPR) were calculated using the combined results.

# Results

We tested three different scoring methods to detect six types of site anomalies introduced at varying degrees across 15 study data sets, donated by three different IMPALA members, with 4 measurement types (Alanine Aminotransferase, Creatinine, Systolic Blood Pressure, Weight). The resulting average True Positive Rate (TPR, also known as Recall) and False Positive Rate (FPR), along with their respective standard deviations, were plotted in @fig-results. The figure shows that TPR rates generally increase with higher anomaly rates, while the FPR either remains flat or slightly decreases as the degree of anomaly increases.

Overall, the mixed effects modeling method emerged as the most robust approach for detecting site-level anomalies, providing a good balance between high TPR and low FPR. The average feature value method, while effective in identifying true positives, was less reliable due to its high false positive rate. 

Among the three site flagging methods, we observed that the average feature value method achieved the highest TPR, detecting almost all high-degree anomalies. However, it also had significantly higher FPR rates compared to the Kolmogorov-Smirnov (KS) method and mixed effects modeling. The KS method had the lowest TPR but almost zero FPR. Mixed Effects Modeling demonstrated the best overall performance, with a TPR surpassing that of the KS method and a negligible rate of false positives.

We did not observe strong differences between the four different measurement types. Some were more susceptible to anomalies, resulting in higher TPR at lower anomaly degrees. This is expected, as anomalies were introduced by multiplying existing measurements, which are more sensitive to higher starting values. 

Further, we observed an overall decrease in the TPR for weight, specifically for the unique value ratio and autocorrelation anomalies. Weight measurements are unique because three out of 15 studies had only one planned weight measurement per patient. Autocorrelation and unique value count ratio require longer time series to become detectable and cannot be introduced into a time series of length one. On top of that weight results tend to have a high frequency of rounding, leading to fewer unique values per time series. TPR for weight for the other anomaly time series pairs is not affected by these specific characteristics of weight measurements.

This underscores the importance of considering the nature of the data when interpreting the performance of anomaly detection methods.

Autocorrelation and LOF anomalies are conceptually more complex than the other time series feature anomaly pairs. Even though the anomalies introduced were extreme, they could not always be detected by an increase in the time series features of the anomalous sites. Using the mixed effect site flagging method, we detected fewer than 50% of all anomalous sites.


# Discussion

Altogether this evaluation of the CTAS algorithm has shown that site-level timeseries anomalies can be detected by comparing summary statistics of individual timeseries from one site against those obtained from all other patients from the study. Of all tested site flagging methods mixed effect modelling has shown the most robust TPR FPR trade-off. In practice mixed effect modelling will also control for regional and country effects that were removed in our validation data sets, further decreasing FPR.

Previously published central SDM strategies select a number of data type appropriate statistical tests to identify site anomalies. They also employ mixed effect models to account for different variability among sites and multiplicity correction @desmet_linear_2014 @trotta_detection_2019 and demonstrate that their application can improve data quality over time @de_viron_does_2024. Presently there is no open source application for these methods.

In general small samples tend to have a higher variability than large samples. Thus small or late starting sites with a low number of subjects or time points are more likely to have extreme values when continuously monitoring ongoing trial data. Most statistical tests will control for a difference in sample size and will reliably flag site outliers among sites with different number of subjects. But smaller differences remain easier to detect in larger samples and differences it smaller samples need to be larger in order to get detected.

The ratio of small sites with less than 3 patients in an average study can be quite high and has been roughly 20% in the investigated studies. The overall maximum performance depends on how well these sites can be detected therefore we chose not to exclude any sites although others have excluded sites with only one patient @trotta_detection_2019. This is why we see a lower maximum TPR when using the Kolmogorov-Smirnov site scoring method because it uses a rank-based test that is somewhat indifferent to the magnitude of the outlier. The mixed effect model scoring method also employed by other methods @desmet_linear_2014 @trotta_detection_2019 accounts for sample number and magnitude but assumes a normal distribution and has an increased FPR compared to the non-parametric Kolmogorov-Smirnov method. To account for the lower TPR that can be expected for small site we recommend to also check for patient-level outliers using similarity plot as depicted in @fig-similarity-plot.

Sample-size induced variability can also be introduced by differences in the number of subject visits. Some measurements will also depend on procedures planned at different visits determined by the study protocol thus different values can be expected for early screening visits compared to late follow up visits. CTAS controls for this by only comparing summary metrics from time series composed of the same time points. Thus CTAS avoids errors introduced by comparing aggregates from samples of different sizes and variability introduced by the study protocol.

We have picked four different measurement types (Alanine Aminotransferase, Creatinine, Systolic Blood Pressure, Weight) across 15 studies to investigate the variability of the results. We did observe slightly different TRP rates across the different anomalies that were introduced. Weight was standing out in particular as the FPR was reduced for unique value ratio and autocorrelation. We attribute this to a prevalance of rounding and that three out of 15 studies only had 1 planned weight measurement per patient. Nevertheless other anomalies could be efficiently detected.

The most complex anomalies introduced were autocorrelation and LOF their corresponding TPR rates were comparatively low when compared to the other anomalies. Even though extreme values were introduced we could not detect the corresponding elevated time series feature values among the signal of the unaltered time series. This shows a high level of noise that is present in the test data sets in regard to those time series features.

In practice extreme values in the data set will not only change one but many time series features. Thus there is a good change that anomalies in the data will create multiple signals that complement each other. CTAS does not try to preemptively select the most appropriate statistical test for a given measurement type and time series length. Therefore all timeseries features can always be measured across all timeseries to cast a wide net for detecting anomalies. 

CTAS does not offer built-in native support for categorical, ordinal and date type data they can be transformed to a numerical data type before running CTAS. This is expected to provide similar results as specifically adapted tests for these data types although this remains to be tested but would require a different strategy for introducing anomalies which would exceed the scope of this work.

# Conclusion

Current regulatory guidelines promote the use of risk based quality monitoring (RBQM) in clinical trials to support traditional onsite monitoring, medical review and data management.

We have demonstrated that the CTAS algorithm can be used to detect site-level anomalies of various kinds and that its accuracy increases the more extreme the anomalies become. Within an RBQM framework, CTAS can screen clinical data for site anomalies and flag cases for manual review. The higher the score the more likely a site is to represent a genuine outlier that can be confirmed in a time series data visualization. The algorithm can be adapted to all data types covering the entire clinical data set, blind spots not covered by manual risk mitigation strategies can be avoided, possible unforeseen scenarios missed by first line control activities (programmed edit checks) can be detected.

Similar tools have been shown to improve data quality over time @de_viron_does_2024. CTAS having the advantage of being better adapted to time series data. The CTAS R package is also available as an open source R package and provides greater transparency as individual in-sourced solutions. By promoting the adoption of CTAS among IMPALA's 19 industry members and enhancing compatibility with other open-source RBQM tools @wu_good_2024, we aim to contribute to the advancement of robust, transparent site anomaly detection in clinical trials.

# Funding statements


No specific funding was provided for the writing of this paper. The IMPALA (Inter coMPany quALity Analytics) Consortium provided funding for the Open Access fees.

# Author Contributions

PT designed the CTAS algorithm, and wrote the R package. All authors participated in the validation and debugging of CTAS and wrote the manuscript. All authors read and approved the final version.


# Figure Legends

@fig-timeseries-def Simplified example of time series definition. Blue cells denote subjects with a measurement at a given time point. Two time series have been defined. TS1 includes subjects (S1-S3) which have finished the study while the second time series (TS2) focuses on the first four time points and includes also subjects S4-S6 in addition to those in the TS1. Remaining subjects have data for too few time points to be considered in either of the time series.

@fig-timeseries-feats Example of a time series with four time points and the features calculated from it. There is one feature which needs more explanation: site co-clustering - a measure of how similar the time series is to other subjects from the same site vs. subjects from all other sites. It is used to identify sites whose time series for a particular parameter are more similar to each other than could be expected by chance. In the extreme case, this could be indicative of sample splitting, i.e., a type of fraud where samples are collected from only one individual but assigned to several subjects. Figure 3 illustrates how co-clustering is calculated for a single time series.

<!--
< BK: not referenced in text
@fig-co-clustering Calculating a site co-clustering feature for a time series. Spheres on the left represent individual time series (red = time series for which we are calculating the feature (query), pink = time series of other subjects from the same site, white = time series of subjects from other sites). First the time series are ranked based on their distance to the query. A ROC curve is calculated for the ranked time series and a Area Under Curve (AUC) is calculated for the curve. The AUC is then used as the co-clustering feature. A feature of value of 1 means that fellow subjects from the same site are all closer to the query than subjects from other sites. A value of zero is the opposite of this and the value 0.5 means that there is no difference between subjects from the query's own site and the subjects from other sites.
-->

@fig-site-flagging Example of site flagging. The timeseries has eight time points and the question is whether the site (six subjects) has reported fewer unique values per time series than other sites in the study. Part 1) has the individual subject time series and the unique value counts. It is clear from the histograms (2) that the site is biased when compared to other sites. To quantify the bias, the distributions are compared with the Kolmogorov-Smirnov test (3) which gives us a raw p-value. As we perform several tests per study, the p-value must be corrected (4). Finally, the negative logarithm of the corrected p-value is taken to come up with the final score for the site (5).

<!--
> BK: not referenced in text

@fig-co-cluster-example Example of co-clustering of systolic blood pressure profiles. Site X was flagged by the tool for a significant bias in the site co-clustering feature. This is evident in the time series (1) as almost all measurements are within the narrow range of 120 to 140 mmHg whereas measurements from other sites vary over a wider range (blue lines). This is also evident in the similarity plot (2) which visualizes the relative distance between time series. On this plot, almost all Site X subjects (filled circles) are clearly co-clustered.

@fig-average-example Example of a site with systematically large values for a laboratory assay. The difference in the average results is clear in both the histogram (1) and the individual time series (2).
-->

@fig-similarity-plot An anomalous weight profile identified based on its distance from other profiles on the similarity plot (left). The profile is given on the right with a sudden drop in weight followed by a return to the previous values. In this case, the reason is probably a data entry error at site.

@fig-sd-example Identifying an individual time series outlier based on a time series feature. In this case the subject with most variable bilirubin profile (1) has been selected and highlighted with the other subjects (2). In this case, it is possible that the site has collected the data correctly but this might be interesting for someone performing medical review to identify safety issues, for example.

@fig-anomalies Simulated site-level anomalies of of varying degree across different anomaly types based on a simulated test data set. Timelines from regular sites are shown in grey and timelines from an anomalous site in red. 

@fig-results True positive and false positive ratio across different simulation scenarios. Ratios are represented as the mean with standard deviation obtained by 15 replicates obtained from simulations based on different studies. Timelines from two laboratory (Alanine Aminotransferase, Creatinine) and 2 vitals mesurements (Systolic Blood Pressure, Weight) were selected to be included in the simulation. The simulations randomly introduced 3 anomalous sites with increasing anomaly degrees into each iteration which needed to be detected by the CTAS algorithm. Study-level ratios were based on simulations with 100 iterations.



# Figures

![Timeseries Definition](timeseries_def.png){#fig-timeseries-def}

![Timeseries Features](timeseries_feats.png){#fig-timeseries-feats}

<!--
> BK: not referenced in text
![Co-Clustering](co_clustering.png){#fig-co-clustering}
-->

![Site Flagging](site_flagging.png){#fig-site-flagging}

<!--
> BK: not referenced in text
![Example Co-Clustering](co_cluster_example.png){#fig-co-cluster-example}

> BK: not referenced in text
![Example Average](average_example.png){#fig-average-example}
-->

![Similarity Plot](similarity_plot.png){#fig-similarity-plot}

![Example Standard Deviation](sd_example.png){#fig-sd-example}


```{r echo=FALSE}
anomaly_names <- c(
      "Average",
      "Standard Deviation",
      "Range",
      "Unique Value Ratio",
      "Auto Correlation",
      "Local Outlier Factor"
    )
```


```{r echo=FALSE, fig.width=10, fig.height=9, warning=FALSE, message=FALSE}
#| label: fig-anomalies
#| fig-cap: "Anomalies"

set.seed(1)

df_prep <- prep_sdtm_lb(pharmaversesdtm::lb, pharmaversesdtm::dm, scramble = TRUE)

df_filt <- df_prep %>%
  filter(parameter_id == "Alkaline Phosphatase") %>%
  mutate(
    timepoint_rank = dense_rank(timepoint_rank)
  )


set.seed(1)

# with this wrapper functions will always generate an anomalous site with the same patients
set_seed <- function(fun, seed = 1){
  fun_seeded <- function(...) {
    set.seed(seed)
    fun(...)
  }
}

df_anomaly <- tibble(
    anomaly_fun = list(
      anomaly_average,
      anomaly_sd,
      anomaly_range,
      anomaly_unique_value_count_relative,
      anomaly_autocorr2,
      anomaly_lof
    ),
    anomaly = anomaly_names
  ) %>%
  mutate(
    anomaly_degree = list(c(0.25, 0.5, 0.75, 1, 5, 10))
  ) %>%
  unnest(anomaly_degree) %>%
  mutate(
    anomaly_fun = map(anomaly_fun, ~ set_seed(., seed = 4)),
    data = map2(anomaly_fun, anomaly_degree, ~ .x(df_filt, .y))
  ) %>%
  unnest(data) %>%
  arrange(subject_id, timepoint_rank) %>%
  mutate(
    is_lim = ifelse(result > 4000, "out of range", ""),
    result_cap_max = ifelse(result > 4000, 4000, result),
    result_cap_NA = ifelse(result_cap_max >= 4000 & lag(result_cap_max) > 4000, NA, result_cap_max),
    .by = subject_id
  )


df_filt_exp <- df_filt %>%
  mutate(
    anomaly = list(unique(df_anomaly$anomaly))
  ) %>%
  unnest(anomaly) %>%
  mutate(
    result = ifelse(anomaly == "Unique Value Ratio" & result > 250, NA, result)
  )

df_anomaly$anomaly <- factor(df_anomaly$anomaly, levels = anomaly_names)
df_filt_exp$anomaly <- factor(df_filt_exp$anomaly, levels = anomaly_names)

ggplot(df_filt_exp, aes(x = timepoint_rank, y = result, group = subject_id)) +
  geom_line(color = "darkgrey", alpha = 0.5) +
  geom_line(data = df_anomaly, aes(y = result_cap_NA), color = "#E72A8A", alpha = 0.5) +
  geom_point(data = df_anomaly, aes(y = result_cap_max, shape = is_lim), color = "#E72A8A", alpha = 0.5) +
  scale_shape_manual(values = c(NA, 3)) +
  facet_grid(anomaly ~ anomaly_degree, scales = "free_y") +
  theme_ctas() +
  theme(legend.position = "bottom") +
  labs(x = "Timepoint Rank", y = "Alkaline Phosphatase U/L", shape = "")

```

```{r results, echo=FALSE, warning=FALSE, message=FALSE}


path <- here::here("inst/pub/")


# Read the data from the specified file
evaluation_results <- read.delim2(file.path(path, "evaluation_results.txt"))

# Recode the feats column
evaluation_results <- evaluation_results %>%
  mutate(feats = recode(feats,
                        "autocorr" = "Auto Correlation",
                        "average" = "Average",
                        "lof" = "Local Outlier Factor",
                        "range" = "Range",
                        "sd" = "Standard Deviation",
                        "unique_value_count_relative" = "Unique Value Ratio"),
         site_scoring_method = recode(site_scoring_method,
                                      "ks" = "K-S",
                                      "mixedeffects" = "Mixed Effects",
                                      "avg_feat_value" = "Average Feature Value"))

# Aggregate data by averaging tpr and fpr and calculating standard deviation
df_agg <- evaluation_results %>%
  group_by(anomaly_degree, feats, parameter_id, site_scoring_method) %>%
  summarise(
    avg_tpr = mean(tpr),
    sd_tpr = sd(tpr),
    avg_fpr = mean(fpr),
    sd_fpr = sd(fpr),
    .groups = 'drop'
  )

# Reshape data for plotting
df_long <- df_agg %>%
  pivot_longer(cols = c(avg_tpr, avg_fpr), names_to = "metric", values_to = "value") %>%
  pivot_longer(cols = c(sd_tpr, sd_fpr), names_to = "metric_sd", values_to = "sd_value")

# Filter data for TPR and FPR
df_tpr <- df_long %>% 
  filter(metric == "avg_tpr" & metric_sd == "sd_tpr") %>%
  mutate(
    ymin = value - sd_value,
    ymin = ifelse(ymin < 0, 0, ymin),
    ymax = value + sd_value,
    ymax = ifelse(ymax > 1, 1, ymax)
  )

df_fpr <- df_long %>% 
  filter(metric == "avg_fpr" & metric_sd == "sd_fpr") %>%
  mutate(
    ymin = value - sd_value,
    ymin = ifelse(ymin < 0, 0, ymin),
    ymax = value + sd_value
  )

df_fpr$feats <- factor(df_fpr$feats, levels = anomaly_names)
df_tpr$feats <- factor(df_tpr$feats, levels = anomaly_names)

# Create the TPR plot
p_tpr <- ggplot(df_tpr, aes(x = anomaly_degree, y = value, color = site_scoring_method, group = site_scoring_method)) +
  geom_line(aes(linetype = site_scoring_method)) +
  geom_point(aes(shape = site_scoring_method)) +
  geom_errorbar(aes(ymin = ymin, ymax = ymax, color = site_scoring_method), alpha = 0.9) +
  scale_x_log10(breaks = c(0.01, 0.25, 0.5, 0.75, 1, 5, 10), labels = c("0", "0.25", "0.5", "0.75", "1", "5", "10")) +
  scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  scale_color_manual(values = c("#1B9E77", "#D95F01", "#7570B3")) +
  facet_grid(parameter_id ~ feats, scales = "fixed") +
  labs(x = "Log-Scaled Anomaly Degree", y = "Average TPR (+/- SD)", color = "Site Scoring Method", fill = "Site Scoring Method", shape = "Site Scoring Method", linetype = "Site Scoring Method") +
  theme_bw() +
  theme(
    strip.text = element_text(size = 8, margin = margin(t = 5, r = 5, b = 5, l = 5)),
    axis.text = element_text(size = 8),
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title = element_text(size = 10),
    legend.text = element_text(size = 8),
    legend.title = element_text(size = 10),
    plot.title = element_text(size = 12, face = "bold"),
    plot.margin = margin(t = 10, r = 10, b = 10, l = 10),
    legend.position = "bottom"
  ) +
  ggtitle("Line Plots of FPR/TPR by Anomaly Degree")


# Create the FPR plot
p_fpr <- ggplot(df_fpr, aes(x = anomaly_degree, y = value, color = site_scoring_method, group = site_scoring_method)) +
  geom_line(aes(linetype = site_scoring_method)) +
  geom_point(aes(shape = site_scoring_method)) +
  geom_errorbar(aes(ymin = ymin, ymax = ymax, color = site_scoring_method), alpha = 0.9) +
  scale_x_log10(breaks = c(0.01, 0.25, 0.5, 0.75, 1, 5, 10), labels = c("0", "0.25", "0.5", "0.75", "1", "5", "10")) +
  scale_y_continuous(breaks = c(0, 0.05, 0.1, 0.15, 0.2, 0.25)) +
  scale_color_manual(values = c("#1B9E77", "#D95F01", "#7570B3")) +
  facet_grid(parameter_id ~ feats, scales = "fixed") +
  labs(x = "Log-Scaled Anomaly Degree", y = "Average TPR (+/- SD)", color = "Site Scoring Method", fill = "Site Scoring Method", shape = "Site Scoring Method", linetype = "Site Scoring Method") +
  theme_bw() +
  theme(
    strip.text = element_text(size = 8, margin = margin(t = 5, r = 5, b = 5, l = 5)),
    axis.text = element_text(size = 8),
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title = element_text(size = 10),
    legend.text = element_text(size = 8),
    legend.title = element_text(size = 10),
    plot.title = element_text(size = 12, face = "bold"),
    plot.margin = margin(t = 10, r = 10, b = 10, l = 10),
    legend.position = "bottom"
  )

```

```{r echo=FALSE, fig.height=14, fig.width=10, warning=FALSE, message=FALSE}
#| label: fig-results
#| fig-cap: 
#|   - "Results"


p_tpr / p_fpr / guide_area() + plot_layout(guides = "collect", axes = "collect", heights = c(1, 1, 0.1))

```


# Tables

| Feature                                      | Anomaly Example                                                                                                                                                                                                                                               |
|:----------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Average value                                | Issues with device calibration for local labs where results are systematically lower or larger due to incorrect measurements.                                                                                                                                 |
| Standard Deviation                           | Large fluctuations in liver enzymes which could be due to a safety reason.                                                                                                                                                                                    |
| Range                                        | Time series with one large peak due to an incorrect original unit assignment.                                                                                                                                                                                 |
| Unique Value Ratio                           | Copied Measurements.                                                                                                                                                                                                                                           |
| Autocorrelation                              | Unexpected linear time series (autocorrelation close to 1) which can be due to the site adding a constant value to the previous measurement.                                                                                                                  |
| Local Outlier Factor (LOF) @breunig_lof_2000 | LOF values greater than one indicate patterns very different from other subjects. In the other extreme, sites where all subjects have LOF values close to one might not have made all the measurements but entering plausible values within ranges of normal. |
: Time Series Features {#tbl-features}





# References

::: {#refs}
:::

# Supporting Material

The CTAS R package is available on github https://github.com/IMPALA-Consortium/ctas as version v0.3.0. The code written for the validation is available in a separate repository https://github.com/IMPALA-Consortium/ctasval version v0.0.5.
