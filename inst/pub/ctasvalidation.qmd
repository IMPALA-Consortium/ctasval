---
title: "ctas validation"
author:
  - name: Pekka Tiikkainen
    corresponding: true
    email: pekka.tiikkainen@bayer.com
    affiliations:
      - Bayer
  - name: Frederik Raphael Colin
    corresponding: false
    email: frederik_raphael.collin@boehringer-ingelheim.com
    affiliations:
      - Boehringer Ingelheim  
  - name: Bj√∂rn Koneswarakantha
    orcid: 0000-0003-4585-7799
    corresponding: false
    email: bjoern.koneswarakantha@roche.com
    affiliations:
      - Roche
output: rmarkdown::html_vignette
toc: true
bibliography: ctas.bib
csl: elsevier-vancouver.csl # https://github.com/citation-style-language/styles/blob/master/elsevier-vancouver.csl
editor_options: 
  chunk_output_type: console
---

```{r include = FALSE}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(purrr))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(tibble))
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(patchwork))

here::i_am("inst/pub/ctasvalidation.qmd")

# Define the custom theme for scientific publications
theme_ctas <- function() theme_bw(base_size = 9)
```

# Author instructions (to be deleted)

## Publishing Requirements TIRS

-   max 5000 words (Word count includes the abstract and full text, but not references, figures, or tables.)
-   structured abstract (Abstract should not exceed 250 words.)
-   https://media.springer.com/full/springer-instructions-for-authors-assets/pdf/1697415_TIRS%20Information%20for%20Authors.pdf

for references add the doi link, I will add those to the `ctas.bib` file.

# Title page (required section)

> The running head for a manuscript will be the shortened manuscript title followed by an ellipsis.

## Abstract

> structured abstract (Abstract should not exceed 250 words.), now 250 words

### Background

Current ICH guidelines advocate a risk-based statistical review of clinical trial data to identify anomalies. The open source R package, clinical trial anomaly spotter (CTAS) has been developed by Bayer and the intercompany quality analytics (IMPALA), helps detect inconsistencies in subject time series data at both site and subject levels, facilitating timely intervention.

### Methods

CTAS analyzes time series of equal length. Each subject-level time series is summarized as six optional scalars mean, standard deviation, range, relative unique value count, autocorrelation and local outlier factor. To detect site-level anomalies sites can be scored using 3 different scoring methods. The performance of the CTAS algorithm was tested using simulations, artificially introducing site anomalies of varying types and degrees into clinical trial data sets.

### Results

We find that CTAS can reliably detect site anomalies depending on the degree of the anomaly introduced. Less complex anomalies such as mean were easier to detect than complex outlier such as local outlier factor. The three scoring methods differed in their ability to detect anomalous sites with a small number of patients and their false positive rate.

### Conclusions

CTAS is a valuable tool for early detection of outliers in clinical data monitoring, suitable for integration into risk-based strategies. Choosing the appropriate site anomaly scoring method is crucial for handling sites with fewer subjects effectively.

# Keywords (required section)

RBQM, SDM, time series, anomaly, clinical trial, outlier

> The journal will publish 5-6 keywords. However, to ensure that your manuscript is easily searchable in PubMed and other repositories, be sure to include any relevant keywords in the title or abstract of your manuscript.

# Introduction (required section)

> The introduction should assume that the reader is knowledgeable in the field and should therefore be brief; it can include a short historical review where desirable. It should also include the study objective.

Most clinical trial data consist of repeated measurements taken of the same patients over the duration of the trial. The integrity of these data points is mostly challenged by systemic errors introduced at site level which can have root causes such as: misinterpretation of the protocol, miscalibration of laboratory tests, insufficient staff training and many more. These errors will affect a larger portion of patients enrolled at the site and should be statistically detectable as site-level anomalies given that sufficient compliant data has been collected within the current trial data set. Classical risk mitigation strategies consist of a combination of monitoring activities such as source data verification (SDV) and source date review (SDR), programmed data management edit checks and medical data review.

Ensuring the high quality of data is a major responsibility of the clinical trial sponsor. Current ICH guidelines recommended a risk-based statistical approach to monitor the completeness, expected range and variability of the clinical trial data @noauthor_ich_1997 So called central monitoring activities are part of the risk-based quality monitoring (RBQM) framework one of which is statistical data monitoring (SDM).

Subject-level data in clinical trial can be collected as categorical, ordinal or numerical data as a single measurement or as a timeseries. Classically all of these data types require different statistical tests. Consequently, statistical data monitoring tools execute a myriad of test @venet_statistical_2012, @kirkwood_application_2013, @trotta_detection_2019 and it has been shown that the application of such tools can improve data quality over time @de_viron_does_2024 Recently an RBQM open source solution focusing on the monitoring of site key risk indicators (KRI) has been published @wu_good_2024 but presently, no open source solution has been published aggregating central data monitoring methods into one tool.

In this paper, we present an evaluation of Clinical Trial Anomaly Spotter (CTAS) - an open-source R package for the identification of anomalous time series collected during the study. The package was developed originally by Bayer, and later co-developed by the Intercompany Quality Analytics (IMPALA) consortium. IMPALA has currently 19 industry members and promotes the use and development of analytics for GxP quality assurance. CTAS fills the statistical data monitoring gap of the current open source RBQM landscape. It has foremost been developed for the detection of anomalies in numerical time series data at site and subject level. CTAS strong focus on time series data ensures that only time series of the same length are being compared suppressing false positive signals.

Here we demonstrate the efficiency of detecting anomalous sites using simulations based on data from 15 clinical trials donated by three of the IMPALA member companies.

# Methods (required section)

> This section should contain sufficient detail, so that all experimental procedures can be reproduced, and include references. Methods, however, that have been published in detail elsewhere should not be described in detail. Authors should provide the name of the manufacturer and their location for any specifically named equipment and instruments, and all drugs should be identified by their pharmaceutical names, with their trade name, if relevant, in parentheses following, at first use. Please carefully read the "Editorial Policies" section for information about animal handling, informed consent, and IRB approval.

## Algorithm

### PROCESSING TIMESERIES

The starting point of CTAS is a set of clinical trial data. The first step the user must make is to transform the data into the format accepted by CTAS. Details on the CTAS data format is described at the project Github repository.

The user is free to include data from any data domain as long as the data is numerical. It is also left to the discretion of the user to either only analyze study critical parameters such as those related to safety and end points or to search for anomalies in all numerical data collected within the study.

The CTAS input arguments give the user plenty of flexibility in defining time points that constitute a time series. Alternatively, the package can be given the freedom of defining time series in a data-driven manner. Additionally, the arguments can be used to restrict the time series features calculated (see below more on these) and choose the site-scoring method (also, see below).

#### DEFINING TIME SERIES

By default, a time series must have at least three time points, there must be at least three eligible subjects per time series, and a subject can have at most half of time points missing. These parameters can of course be changed by the user to fit the characteristics of the trial better.

The user can also have baseline-adjusted time series generated if baseline values are defined.

In an on-going study, some subjects might have only taken the first visits while some have already finished the study. This is the reason why more than one time series per parameter can be defined. For example, one time series would include almost all planned time points and would be useful for comparing sites and subjects which have largely finished the trial. Another time series might focus on the first few visits to also include subjects which have only lately been enrolled. @fig-timeseries-def gives a simplified example of a set of two time series defined for a parameter.

#### TIME SERIES FEATURES

Each time series is characterized by set of time series features. These features are central to the algorithm as they are used to flag anomalous sites (see below). In addition, the features can be used to identify individual subjects with peculiar time series. Currently available time series features are listed in the table below. For an illustration of features for a time series, please see @fig-timeseries-feats.

| Feature code | Description |
|-------------------------|-----------------------------------------------|
| autocorr | Auto-correlation |
| average | Average value |
| own_site_simil_score | Measure of co-clustering of time series from the same study site |
| sd | Standard deviation |
| unique_value_count_relative | Number of unique values divided by number of values available |
| range | Maximum difference between two time points in a series |
| lof | Local Outlier Factor. Values around one are inliers while the larger the value, more of an outlier the timeseries is. |

: List of time series features

### FLAGGING SITES

> BK: we need to mention the three different site scoring methods

Flagging sites with a systematic bias in their time series is an important part of study monitoring. If identified early enough, the site can be offered further training if the site has had trouble in interpreting the study protocol. In the extreme case, if the bias is due to intentional misconduct, the site can be closed and excluded from analysis.

Sites are flagged based on the bias in their time series feature values versus other sites in the study. The user has three options for flagging the sites: Kolmogov-Smirnov, Mixed effects modelling and the simple average of the feature values.

#### Kolmogorov-Smirnov

The Kolmogorov-Smirnov (K-S) statistical test compares time series feature values of individual sites against the combined values from all other sites. This non-parametric test evaluates the null hypothesis that the feature values from a specific site and the feature values from all other sites are drawn from the same distribution.

The K-S test calculates the maximum difference between the empirical cumulative distribution functions (ECDFs) of the two samples, providing a D-statistic and a p-value for each comparison. The p-value indicates the significance of the difference between the distributions. A low p-value suggests that the feature values from the site are significantly different from those of other sites, potentially indicating an anomaly.

It is important to note that, unlike the mixed effects model, the K-S test does not implicitly account for region and country-level demographic factors that might affect site scoring. For example, demographic differences such as lower body weight in East Asian countries could lead to sites from these regions being flagged for lower body weight than expected. This limitation should be considered when interpreting the results, as demographic factors may contribute to the observed differences in feature values.

@fig-site-flagging gives an example on how the method is used to identify a site with relatively few unique values per time series.

#### Mixed effects modelling

This approach allows us to account for both fixed and random effects in the data, providing a robust framework for detecting anomalies. 

We fit a mixed effects model to the data, where the hierarchical structure of the data is taken into account by including random effects for different levels (i.e., sites nested within countries and regions). After fitting the model, we simulate the random effects to obtain estimates for each entity (sites, countries, and regions). For each entity, we calculate the median and standard deviation of the random effects. Additionally, the median and standard deviation are used to calculate a p-value for each entity's deviation from zero, providing a statistical measure of the significance of the bias.

One significant advantage of using mixed effects models in this context is their ability to account for region-level and country-level demographic factors when scoring sites. By incorporating these higher-level random effects, the model can more accurately detect site-specific biases while controlling for broader demographic influences. This approach provides a comprehensive understanding of potential biases across different study sites, countries, and regions.

#### Average feature value

As a simple baseline model for anomaly detection, we also scored sites based on the average feature values of the subjects at each site. This straightforward approach involves calculating the mean feature value for each site and using these averages to identify potential anomalies. In the validation below, we have involved this mainly to have a benchmark to see if the more complex site flagging methods are able to outperform it.

The primary advantage of this method is its simplicity and ease of understanding. It provides a clear and straightforward way to identify sites with unusual feature values. However, this approach does not take into account the size of the site. A site with only one subject who has an extreme feature value may get flagged, even though this could be due to chance alone and may not indicate a systematic issue with the site. Like the Kolmogorov-Smirnov approach, this method does not account for region and country-level demographic factors that might influence feature values.

### IDENTIFYING ANOMALIES IN INDIVIDUAL TIME SERIES

> BK: consider removing this sections if we run out of space, as we do not include it in validation

In addition to flagging sites, the results are valuable for identifying individual subjects with anomalous time series. Sites which exhibit no systematic bias might still contain individual anomalous subjects and time series. One way is to visually inspect similarity plots for subjects with few near neighbors. @fig-similarity-plot gives an example of this for an anomalous weight profile. Another approach is to compare time series features and review time series with extreme values for one or more of these. Please see @fig-sd-example for an example on this. Please note that outliers identified with the two approaches often correlate, e.g., subjects with unusually high standard deviations also tend to be outliers on the similarity plot.

## Validation

To evaluate CTAS performance for detecting sites with anomalous time series we selected data from two laboratory (Alanine Aminotransferase, Creatinine) and two vitals measurements (Systolic Blood Pressure, Weight) from a clinical trial data set and reassigned all patients to different sites to eliminate any existing site-specific anomalies. Further we removed data points from unscheduled visits and data from screening failures. In total, 15 completed studies were selected from 3 different IMPALA members in triplicates with comparable patient and site number.

For each anomaly in scope we applied a specific transformation with a given degree to the measurements of three randomly selected sites. (i) Autocorrelation was introduced by adding a sinus signal multiplied by the anomaly degree to the original values. (ii) The average was increased by adding the site mean multiplied by the anomaly degree to the original values. (iii) The local outlier factor for a site would be increased by transforming the data for each patient by a randomly chosen non-normal distribution. The anomaly degree would determine the ratio of affected patients. (iv) To simulate range outliers we added one outlier per patient. The extremity of the outlier is based on the anomaly degree. (v) The standard deviation is increased by adding the site mean multiplied with the anomaly degree to each observations and randomly applying a negative or positive fore-sign. (vi) The unique value count per site was increased by replacing a ratio of observations with the first observed value per patient. The ratio would be determined by the anomaly degree. The anomalies introduced are visualized in @fig-anomalies.

Subsequently we tried to detect the three anomalous sites using different site scoring methods among the compliant sites in the study data set. For each site we used the highest CTAS score and employed a threshold of 1.3 if applicable. This was repeated a 100 times and true positive rate (TPR) and false positive rate (FPR) were calculated using the combined results.

# Results (required section)

> The Results section should briefly present the experimental data in text, tables or figures. Tables and figures should not be described extensively in the text.

We have tested three different scoring methods trying to detect 6 different types of site anomalies that were introduced with varying degrees to 15 study data sets donated by 3 different IMPALA members across 4 different timeseries metrics. The resulting average TPR and FPR with their respective standard deviations were plotted in @fig-results which shows that TPR are responsive to the degree of the anomlies that were introduced while FPR remain indifferent.

We observe that the average method has the highest TPR detecting almost all high degree anomalies at the cost of having the highest FPR among the scoring methods that we tested. The ks method has the lowest FPR but also the lowest TPR. While the mixedeffects and the average method both are able to detect simpler high degree anomalies, such as anomalies increasing the site average, with relative certainty the ks method struggles to detect more than half of the sites with such high degree anomalies.

> BK we need to see how this holds up, when adding more data.

We do not observe strong differences between the timeseries metrics. Some of them are more suceptible to the introduction of the anomalies and tend to result in higher TPR at lower anomaly degrees. This is to be expected as the anomalies use multiplication of the existing measurement that are more sensitive to higher starting values. An exception is the weight metric for which ctase only reaches a TPR of less than 0.5 when trying to detect unique value outliers.

Autocorrelation and local outlier factor anomalies which are more complex than the other anomalies are also difficult to detect we bareley detected half of the outliers that were introduced.

# Discussion (required section)

> The Discussion should focus on the interpretation and the significance of the findings with concise objective comments that describe their relation to other work in the area. It should not repeat information in the results.

Alltogether this evaluation of the CTAS algorithm has shown that site-level timeseries anomalies can be detected by comparing summary statistics of individual timeseries from one site against those obtained from all other patients from the study.

Previously published SDM strategies select a number of data type appropriate statistical tests to identify site anomalies. They also employ mixed effect models to account for different variablility among sites and multiplicity correction @desmet_linear_2014 @trotta_detection_2019 and demonstrate that their application can improve data quality over time @de_viron_does_2024. Presently there is no open source application for these methods.

In general small samples tend to have a higher variablity than large samples. Thus small or late starting sites with a low number of subjects or timepoints are more likely to have extreme values when continuously monitoring ongoing trial data. Most statistical tests will control for a difference in sample size and will reliably flag site outliers among sites with different number of subjects. But smaller differences remain easier to detect in larger samples and differences it smaller samples need to be larger in order to get detected.

The ratio of small sites with less than 3 patients in an average study can be quite high and has been roughly 20% in the investigated studies. The overall maximum performance depends on how well these sites can be detected therefore we chose not to exclude any sites although others have excluded sites with only one patient @trotta_detection_2019. This is why we see a lower maximum TPR when using the Kolmogorov-Smirnov site scoring method because it uses a rank-based test that is somewhat indifferent to the magnitude of the outlier. The mixed effect model scoring method also employed by other methods @desmet_linear_2014 @trotta_detection_2019 accounts for sample number and magnitude but assumes a normal distribution and has an increased FPR compated to the non-parametric Kolmogorov-Smirnov method. To account for the lower TPR that can be expected for small site we recommend to also check for patient-level outliers using similarity plot as depicted in @fig-similarity-plot.

Sample-size induced variability can also be introduced by differences in the number of subject visits. Some measurements will also depend on procedures planned at different visits determined by the study protocol thus different values can be expected for early screening visits compared to late follow up visits. CTAS controls for this by only comparing summary metrics from time series with the same length. Thus CTAS avoids errors introduced by comparing aggregates from samples of different sizes and variablitly introduced by the study protocol.

> BK: Maybe we could have a paragraph discussing time series length here. But so far I do not understand it well myself.

While the number of patients at a site is an important factor that determines whether site anomalies can be statistically detected the length of the individual time series is also important.

The explanation here is that the majority of the studies only measured weight during screening. For a timeseries of length one all patients will have a relative unique value count of 1.

> BK Here we need to say something about the more complex anomalies lof and autocorr, not sure exactly yet what to say about autocorr

Local outlier factor creates a multidimensional distance metric that is hard to emulate artificially. Nevertheless the approach to transform patients measurement by a random non-normal distribution could increase the distance of the anomolous site to the rest of the data set to some extend. And CTAS was able to detect around 50% of the anomolous sites.

Nevertheless all 6 summary metrics collected by CTAS complement each other and any site-level anomaly will affect more than one metric.

Although CTAS does not offer built-in native support for categorical, ordinal and date type data they can be transformed to a numerical data type before running CTAS. This is expected to provide similar results as specifically adapted tests for these data types although this remains to be tested but would require a different strategy for introducing anomalies which would exceed the scope of this work.

# Conclusion (required section)

> The conclusions section should highlight the main conclusion(s), stating the answer to the study objective. The Conclusions section should be a distinct section.

Current regulatory guidelines promote the use of risk based quality monitoring (RBQM) in clinical trials to support traditional onsite monitoring and medical review and data management.

We have demonstrated that the CTAS algorithm can be used to detect site-level anomalies of various kinds and that it gets more accurrate the more extreme the anomalies are. Within an RBQM framework CTAS can be used to screen a clinical data set for site anomalies and target those for manual data review. The higher the score the more likely a site is to represent a genuine outlier that can be confirmed in a time series data visualisation. The algorithm can be adapted to all data types covering the entire clinical data set, blind spots not covered by manual risk mitigation strategies can be avoided, possible unforeseen scenarios missed by first line control activities (programmed edit checks) can be detected.

Similar tools have been shown to improve data quality over time @de_viron_does_2024 with CTAS having the advantage of being better adapted to time series data. The CTAS R package is also available as an open source R package and provides greater transparency as individual in-sourced solutions. We aim to promote the adoption of CTAS among IMPALA's 19 industry members and to drive the compatibility with other open source RBQM tools @wu_good_2024.

# Funding statements (required section)

> The Funding section is mandatory. Authors must declare sources of study funding including sponsorship (e.g. university, charity, commercial organization) and sources of material (e.g. novel drugs) not available commercially. See the Editorial Policy section for detailed information and requirements on this section. This section should also include, if desired, special thanks or dedications. Work done by a contributor or medical writer that does not qualify him/her for authorship, but which warrants acknowledgement, should be noted here.

No specific funding was provided for the writing of this paper. The IMPALA (Inter coMPany quALity Analytics) Consortium provided funding for the Open Access fees.

# Author Contributions (required section)

PT designed the CTAS algorithm, and wrote the R package. All authors participated in the validation and debugging of CTAS and wrote the manuscript. All authors read and approved the final version.

> A statement outlining each author's contributions is mandatory. In order to meet requirements of authorship, each author must have contributed to at least one of the aspects below. The ICMJE and Therapeutic Innovation & Regulatory Science considers authorship to be based on the following four criteria: ÔÇ∑ Substantial contributions to the conception or design of the work; or the acquisition, analysis, or interpretation of data for the work; and ÔÇ∑ Drafting the work or revising it critically for important intellectual content; and ÔÇ∑ Final approval of the version to be published; and ÔÇ∑ Agreement to be accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved. Additional information can be found under "Authorship." As per ICMJE best practice, information provided in this section is the responsibility of the authors.

# Figure Legends

@fig-timeseries-def Simplified example of time series definition. Blue cells denote subjects with a measurement at a given time point. Two time series have been defined. TS1 includes subjects (S1-S3) which have finished the study while the second time series (TS2) focuses on the first four time points and includes also subjects S4-S6 in addition to those in the TS1. Remaining subjects have data for too few time points to be considered in either of the time series.

@fig-timeseries-feats Example of a time series with four time points and the features calculated from it. There is one feature which needs more explanation: site co-clustering - a measure of how similar the time series is to other subjects from the same site vs. subjects from all other sites. It is used to identify sites whose time series for a particular parameter are more similar to each other than could be expected by chance. In the extreme case, this could be indicative of sample splitting, i.e., a type of fraud where samples are collected from only one individual but assigned to several subjects. Figure 3 illustrates how co-clustering is calculated for a single time series.

@fig-co-clustering Calculating a site co-clustering feature for a time series. Spheres on the left represent individual time series (red = time series for which we are calculating the feature (query), pink = time series of other subjects from the same site, white = time series of subjects from other sites). First the time series are ranked based on their distance to the query. A ROC curve is calculated for the ranked time series and a Area Under Curve (AUC) is calculated for the curve. The AUC is then used as the co-clustering feature. A feature of value of 1 means that fellow subjects from the same site are all closer to the query than subjects from other sites. A value of zero is the opposite of this and the value 0.5 means that there is no difference between subjects from the query's own site and the subjects from other sites.

@fig-site-flagging Example of site flagging. The timeseries has eight time points and the question is whether the site (six subjects) has reported fewer unique values per time series than other sites in the study. Part 1) has the individual subject time series and the unique value counts. It is clear from the histograms (2) that the site is biased when compared to other sites. To quantify the bias, the distributions are compared with the Kolmogorov-Smirnov test (3) which gives us a raw p-value. As we perform several tests per study, the p-value must be corrected (4). Finally, the negative logarithm of the corrected p-value is taken to come up with the final score for the site (5).

@fig-co-cluster-example Example of co-clustering of systolic blood pressure profiles. Site X was flagged by the tool for a significant bias in the site co-clustering feature. This is evident in the time series (1) as almost all measurements are within the narrow range of 120 to 140 mmHg whereas measurements from other sites vary over a wider range (blue lines). This is also evident in the similarity plot (2) which visualizes the relative distance between time series. On this plot, almost all Site X subjects (filled circles) are clearly co-clustered.

@fig-average-example Example of a site with systematically large values for a laboratory assay. The difference in the average results is clear in both the histogram (1) and the individual time series (2).

@fig-similarity-plot An anomalous weight profile identified based on its distance from other profiles on the similarity plot (left). The profile is given on the right with a sudden drop in weight followed by a return to the previous values. In this case, the reason is probably a data entry error at site.

@fig-sd-example Identifying an individual time series outlier based on a time series feature. In this case the subject with most variable bilirubin profile (1) has been selected and highlighted with the other subjects (2). In this case, it is possible that the site has collected the data correctly but this might be interesting for someone performing medical review to identify safety issues, for example.

@fig-anomalies Simulated site-level anomalies of of varying degree across different anomaly types. Timelines from regular sites are shown in grey and timelines from an anomalous site in red. The number of patients per anomalous site is sampled from the distribution of the number of patients per site from the original data set.

@fig-results True positive and false positive ratio across different simulation scenarios. Ratios are represented as the mean with standard deviation obtained by 15 replicates obtained from simulations based on different studies. Timelines from two laboratory (Alanine Aminotransferase, Creatinine) and 2 vitals mesurements (Systolic Blood Pressure, Weight) were selected to be included in the simulation. The simulations randomly introduced 3 anomalous sites with increasing anomaly degrees into each iteration which needed to be detected by the CTAS algorithm. Study-level ratios were based on simulations with 100 iterations.

# Tables

> These should be labeled sequentially as Table 1, Table 2, etc. Each table should be typed on a separate page, numbered and titled, and cited in the text. Reference to table footnotes should be made by means of Arabic numerals. Tables should not duplicate the content of the text. They should consist of at least two columns; columns should always have headings. Authors should ensure that the data in the tables are consistent with those cited in the relevant places in the text, totals add up correctly, and percentages have been calculated correctly. Tables may be either included in the article file itself, but at the end of the manuscript, or supplied as separate files.

# Figures

![Timeseries Definition](timeseries_def.png){#fig-timeseries-def}

![Timeseries Features](timeseries_feats.png){#fig-timeseries-feats}

![Co-Clustering](co_clustering.png){#fig-co-clustering}

![Site Flagging](site_flagging.png){#fig-site-flagging}

![Example Co-Clustering](co_cluster_example.png){#fig-co-cluster-example}

![Example Average](average_example.png){#fig-average-example}

![Similarity Plot](similarity_plot.png){#fig-similarity-plot}

![Example Standard Deviation](sd_example.png){#fig-sd-example}

```{r echo=FALSE, fig.width=10, fig.height=9}
#| label: fig-anomalies
#| fig-cap: "Anomalies"

set.seed(1)
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(ctasval))

df_prep <- prep_sdtm_lb(pharmaversesdtm::lb, pharmaversesdtm::dm, scramble = TRUE)

df_filt <- df_prep %>%
  filter(parameter_id == "Alkaline Phosphatase")

set.seed(1)

df_anomaly <- tibble(
    anomaly_fun = list(
      anomaly_autocorr,
      anomaly_average,
      anomaly_lof,
      anomaly_range,
      anomaly_sd,
      anomaly_unique_value_count_relative
    ),
    anomaly = c(
      "autocorr",
      "average",
      "lof",
      "range",
      "sd",
      "unique_value_count_relative"
    )
  ) %>%
  mutate(
    anomaly_degree = list(c(0.25, 0.5, 0.75, 1, 5, 10))
  ) %>%
  unnest(anomaly_degree) %>%
  mutate(
    data = map2(anomaly_fun, anomaly_degree, ~ .x(df_filt, .y))
  ) %>%
  unnest(data)

ggplot(df_filt, aes(x = timepoint_rank, y = result, group = subject_id)) +
  geom_line(color = "darkgrey", alpha = 0.5) +
  geom_line(data = df_anomaly, color = "tomato", alpha = 0.5) +
  facet_grid(anomaly ~ anomaly_degree, scales = "free_y") +
  coord_cartesian(xlim = c(0, 15)) +
  theme_ctas() +
  labs(x = "Timepoint Rank", y = "Alkaline Phosphatase U/L")
  

```

```{r echo=FALSE, fig.height=12, fig.width=10}
#| label: fig-results
#| fig-cap: 
#|   - "Results"

path <- here::here("inst/pub/")

df_results <- tibble(
    files = dir(path, pattern = "collected_results_", full.names = TRUE)
  ) %>%
  mutate(
    data = purrr::map(files, ~ readr::read_csv(., show_col_types = FALSE))
  ) %>%
  unnest(data)

stopifnot(nrow(df_results) > 0)

plot_ratio <- function(df_results, ratio) {
  
  df_results %>%
    mutate(
      ratio = .data[[ratio]],
      ratio = replace_na(ratio, 0),
    ) %>%
    summarise(
      ratio_mean = mean(ratio),
      ratio_lwr = ratio_mean - sd(ratio),
      ratio_lwr = ifelse(ratio_lwr < 0, 0, ratio_lwr),
      ratio_upr = ratio_mean + sd(ratio),
      ratio_upr = ifelse(ratio_upr > 1, 1, ratio_upr),
      .by = c(parameter_id, feats, anomaly_degree, method)
    ) %>%
    ggplot(aes(log(anomaly_degree),  ratio_mean, color = method)) +
    geom_line(aes(color = method), alpha = 0.5) +
    geom_pointrange(aes(ymin = ratio_lwr, ymax = ratio_upr), alpha = 0.5) +
    facet_grid(parameter_id ~ feats) + 
    theme_ctas() +
    theme(legend.position = "bottom")
  
}

p_tpr <- plot_ratio(df_results, ratio = "tpr") +
  labs(
    y = "Average True Positive Ratio (+/- SD)",
    x = "Log Anomaly Degree",
    color = "Site Scoring Method"
  )


p_fpr <- plot_ratio(df_results, ratio = "fpr") +
  labs(
    y = "Average False Positive Ratio (+/- SD)",
    x = "Log Anomaly Degree",
    color = "Site Scoring Method"
  )

p_tpr / p_fpr / guide_area() + plot_layout(guides = "collect", axes = "collect", heights = c(1, 1, 0.1))
```

# References

::: {#refs}
:::

# Supporting Material

The CTAS R package is available on github https://github.com/IMPALA-Consortium/ctas as version v0.3.0 . The code written for the validation is available in a separate repository https://github.com/IMPALA-Consortium/ctasval version v0.0.3 .
