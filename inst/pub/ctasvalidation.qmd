---
title: "ctas validation"
author:
  - name: Pekka Tiikkainen
    corresponding: true
    email: pekka.tiikkainen@bayer.com
    affiliations:
      - Beyer
  - name: Frederik Raphael Colin
    corresponding: false
    email: frederik_raphael.collin@boehringer-ingelheim.com
    affiliations:
      - Boehringer Ingelheim  
  - name: Björn Koneswarakantha
    orcid: 0000-0003-4585-7799
    corresponding: false
    email: bjoern.koneswarakantha@roche.com
    affiliations:
      - Roche
output: rmarkdown::html_vignette
toc: true
bibliography: ctas.bib
csl: elsevier-vancouver.csl # https://github.com/citation-style-language/styles/blob/master/elsevier-vancouver.csl
editor_options: 
  chunk_output_type: console
---

```{r include = FALSE}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(purrr))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(tibble))
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(patchwork))

here::i_am("inst/pub/ctasvalidation.qmd")

# Define the custom theme for scientific publications
theme_ctas <- function() theme_bw(base_size = 9)
```


# Author instructions (to be deleted)

## Publishing Requirements TIRS

-   max 5000 words (Word count includes the abstract and full text, but not references, figures, or tables.)
-   structured abstract (Abstract should not exceed 250 words.)
-   https://media.springer.com/full/springer-instructions-for-authors-assets/pdf/1697415_TIRS%20Information%20for%20Authors.pdf

for references add the doi link, I will add those to the `ctas.bib` file.

# Title page (required section)

> The running head for a manuscript will be the shortened manuscript title followed by an ellipsis.

## Abstract

Correcting errors in clinical trial data as the trial is on-going is vital for an accurate safety and efficacy read-out. In this talk, we will show how time series can be used to identify trial sites and individual subjects with potential errors in their clinical parameters (e.g., vital signs or laboratory measurements). Each subject-level time series is summarized as scalars such as mean and entropy. These features alone are useful in identifying individual subjects with suspicious data. Furthermore, trial sites with systematic bias in their data are flagged (for example, all albumin measurements at a site might have a growing trend while there is no trend at the study level). Results of the algorithm are available to anyone in our development organization who are involved in ensuring the quality of our trial data. Actions resulting from the results can range from sending queries to planning complete study audits.

# Keywords (required section)

The journal will publish 5-6 keywords. However, to ensure that your manuscript is easily searchable in PubMed and other repositories, be sure to include any relevant keywords in the title or abstract of your manuscript.

# Introduction (required section)

> The introduction should assume that the reader is knowledgeable in the field and should therefore be brief; it can include a short historical review where desirable. It should also include the study objective.

> BK: IMPALA needs to be mentioned in abstract and introduction

Ensuring the high quality of data is one of the main tasks of a clinical trial sponsor. This work is done when the study is on-going, and it is an absolute requirement for a solid safety and efficacy readout at the end of the study. If issues are identified early enough, the study site could be further trained to avoid problems later in the study. In the extreme case of fraud, a site can be completely excluded from the study to avoid bias in study results.

There are various ways how sponsors try to ensure that the trial sites record results as defined in the trial protocol. Source data verification aims to catch transcription errors by comparing results in original documentation with what has been entered into the electronic data capture system. At central monitoring, protocol compliance is controlled to ensure that, for example, subject visits take place at correct intervals, or that inclusion and exclusion criteria have been met. Central statistical monitoring screens subject measurements (e.g., laboratory results or vital signs) for any anomalies such as individual measurement outliers.

In this paper, we present an evaluation of CTAS (Clincical Trial Anomaly Spotter) - an open-source R package for the identification of anomalous time series collected during the study. The package was developed originally by Bayer, and later co-developed by the IMPALA consortium. Anomalous time series are monitored both on the level of an individual subject and a trial site. The rest of the paper describes how the time series are processed and analyzed with CTAS. Also an evaluation of the package's performance in picking anomalous data is presented using semi-synthetic clinical trial data sets. Examples of typical anomalies are also given.

**Use for References Examples** Detecting anomalies in timeseries clinical trial data is a complex problem with no standard solution. @chandola_anomaly_2009

Here are some examples on fraud in clinical trials. @george_data_2015

# Methods (required section)

> This section should contain sufficient detail, so that all experimental procedures can be reproduced, and include references. Methods, however, that have been published in detail elsewhere should not be described in detail. Authors should provide the name of the manufacturer and their location for any specifically named equipment and instruments, and all drugs should be identified by their pharmaceutical names, with their trade name, if relevant, in parentheses following, at first use. Please carefully read the "Editorial Policies" section for information about animal handling, informed consent, and IRB approval.

## Algorithm

### PROCESSING TIMESERIES

The starting point of CTAS is a set of clinical trial data. The first step the user must make is to transform the data into the format accepted by CTAS. Details on the CTAS data format is described at the project Github repository.

The user is free to include data from any data domain as long as the data is continuous. It is also left to the discretion of the user to either only analyze study critical parameters such as those related to safety and end points or to search for anomalies in all numerical data collected within the study.

The CTAS input arguments give the user plenty of flexibility in defining time points that constitute a time series. Alternative the package can be given the freedom of defining time series in a data-driven manner. Additionally, the arguments can be used to restrict the time series features calculated (see below more on these) and choose the site-scoring method (also, see below).

#### DEFINING TIME SERIES

By default, a time series must have at least three time points, there must be at least three eligible subjects per time series, and a subject can have at most half of time points missing. These parameters can of course be changed by the user to fit the characteristics of the trial better.

The user can also have baseline-adjusted time series generated if baseline values are defined.

In an on-going study, some subjects might have only taken the first visits while some have already finished the study. This is the reason why more than one time series per parameter can be defined. For example, one time series would include almost all planned time points and would be useful for comparing sites and subjects which have largely finished the trial. Another time series might focus on the first few visits to also include subjects which have only lately been enrolled. @fig-timeseries-def gives a simplified example of a set of two time series defined for a parameter.

#### TIME SERIES FEATURES

Each time series is characterized by set of time series features. These features are central to the algorithm as they are used to flag anomalous sites (see below). In addition, the features can be used to identify individual subjects with peculiar time series. Currently available time series features are listed in the table below. For an illustration of features for a time series, please see @fig-timeseries-feats.

| Feature code | Description |
|------------------------|-----------------------------------------------|
| autocorr | Auto-correlation |
| average | Average value |
| own_site_simil_score | Measure of co-clustering of time series from the same study site |
| sd | Standard deviation |
| unique_value_count_relative | Number of unique values divided by number of values available |
| range | Maximum difference between two time points in a series |
| lof | Local Outlier Factor. Values around one are inliers while the larger the value, more of an outlier the timeseries is. |

: List of time series features

### FLAGGING SITES

> BK: we need to mention the three different site scoring methods

Flagging sites with a systematic bias in their time series is an important part of study monitoring. If identified early enough, the site can be offered further training if the site has had trouble in interpreting the study protocol. In the extreme case, if the bias is due to intentional misconduct, the site can be closed and excluded from analysis.

For each time series and feature, the site's distribution of feature values is compared to the distribution of feature values for subjects enrolled in other sites in the study. Kolmogorov-Smirnov test is used for the comparison. The greater the difference in the two distributions is, the smaller the p-value given by the test is. The p-value is corrected for multiple testing and converted into its negative logarithm which is the site's "biasness" score for the parameter and feature. @fig-site-flagging gives an example on how the method is used to identify a site with relatively few unique values per time series.

### IDENTIFYING ANOMALIES IN INDIVIDUAL TIME SERIES

> BK: consider removing this sections if we run out of space, as we do not include it in validation

In addition to flagging sites, the results are valuable for identifying individual subjects with anomalous time series. Sites which exhibit no systematic bias might still contain individual anomalous subjects and time series. One way is to visually inspect similarity plots for subjects with few near neighbors. @fig-similarity-plot gives an example of this for an anomalous weight profile. Another approach is to compare time series features and review time series with extreme values for one or more of these. Please see @fig-sd-example for an example on this. Please note that outliers identified with the two approaches often correlate, e.g., subjects with unusually high standard deviations also tend to be outliers on the similarity plot.

## Validation

To evaluate ctas performance for detecting sites with anomolus time series we selected data from two laboraty (Alanine Aminotransferase, Creatinine) and two vitals mesurements (Systolic Blood Pressure, Weight) from a clinical trial data set and reassigned all patients to different sites to eliminate any existing site-specific anomalies. Further we removed data points from unscheduled visits and data from screen failed patients. In total 15 completed studies were selected from 3 different IMPALA members in triplicates with comparable patient and site number.

For each anomaly in scope we applied a specific transformation with a given degree to the measurements of three randomly selected sites. (i) Autocorrelation was introduced by adding a sinus signal multiplied by the anomaly degree to the original values. (ii) The average was increased by adding the site mean multiplied by the anomaly degree to the original values. (iii) The local outlier factor for a site would be increased by transforming the data for each patient by a randomly chosen non-normal distribution. The anomaly degree would determine the ratio of affected patients. (iv) To simulate range outliers we added one outlier per patient. The extremity of the outlier is based on the anomaly degree. (v) The standard deviation is increased by adding the site mean multiplied with the anomaly degree to each observations and randomly applying a negative or positive fore-sign. (vi) The unique value count per site was increased by replacing a ratio of observations with the first observed value per patient. The ratio would be determined by the anomaly degree. The anomalies introduced are visualised in @fig-anomalies. 

Subsequently we tried to detect the three anomlous sites using different site scoring methods among the compliant sites in the study data set. This was repeated a 100 times and true positive rate (TPR) and false positive rate (FPR) were calculated using the combined results. 


# Results (required section)

> The Results section should briefly present the experimental data in text, tables or figures. Tables and figures should not be described extensively in the text.

We have tested three different scoring methods trying to detect 6 different types of site anomalies that were introduced with varying degrees to 15 study data sets donated by 3 different IMPALA members across 4 different timeseries metrics. The resulting average TPR and FPR with their respective standard deviations were plotted in @fig-results which shows that TPR are responsive to the degree of the anomlies that were introduced while FPR remain indifferent.

We observe that the average method has the highest TPR detecting almost all high degree anomalies at the cost of having the highest FPR among the scoring methods that we tested. The ks method has the lowest FPR but also the lowest TPR. While the mixedeffects and the average method both are able to detect simpler high degree anomalies, such as anomalies increasing the site average, with relative certainty the ks method struggles to detect more than half of the sites with such high degree anomalies.

> BK we need to see how this holds up, when adding more data.

We do not observe strong differences between the timeseries metrics. Some of them are more suceptible to the introduction of the anomalies and tend to result in higher TPR at lower anomaly degrees. This is to be expected as the anomalies use multiplication of the existing measurement that are more sensitive to higher starting values. An exception is the weight metric for which ctase only reaches a TPR of less than 0.5 when trying to detect unique value outliers. 

Autocorrelation and local outlier factor anomalies which are more complex than the other anomalies are also difficult to detect we bareley detected half of the outliers that were introduced.

# Discussion (required section)

> The Discussion should focus on the interpretation and the significance of the findings with concise objective comments that describe their relation to other work in the area. It should not repeat information in the results.

Alltogether this evaluation of the ctas algorithm has shown that site-level timeseries anomalies can be detected by comparing summary statistics of individual timeseries from one site against those obtained from all other patients from the study. Of all site scoring methods tested the ks and the mixedeffects method have lower TPR than the simpler approach of using boxplot statistics on site average values to detect outlier. The ks method has the lowest TPR overall but fails to detect all anomalies introduced even whith very high anomaly deegrees. The ks method is a rank-based test and does not account for the magnitude of an observed difference between two groups. Therefore sites with less than three patients will never be assigned a low p-value and thus will never get detected as an anomolous site. The ratio of such small sites across all of the studies is roughly 20% which explains the lower TPR when using the ks method. Even though the mixedeffect model method can detect site-level anomalies for small sites the anomalies will need to be more extreme and we need to tolereate a higher level of noise as the FPR will increase. The ctas algorithm is targeted to detect systemic anomalies at site-level and not to detect outliers for individual patients, although they might contribute to a site's signal. We therefore recommend to also check for patient-level outliers using similarity plot as depicted in @fig-similarity-plot.

> BK: Maybe we could have a paragraph discussing time series length here. But so far I do not understand it well myself. 

While the number of patients at a site is an important factor that determines whether site anomalies can be statistically detected the length of the individual time series is also important.

The explanation here is that the majority of the studies only measured weight during screening. For a timeseries of length one all patients will have a relative unique value count of 1.

> BK Here we need to say something about the more complex anomalies lof and autocorr, not sure exactly yet what to say about autocorr

Local outlier factor creates a multidimensional distance metric that is hard to emulate artificially. Nevertheless the approach to transform patients measurement by a random non-normal distribution could increase the distance of the anomolous site to the rest of the data set to some extend. And ctas was able to detect around 50% of the anomolous sites.

Nevertheless all 6 summary metrics collected by ctas complement each other and any site-level anomaly will affect more than one metric.

# Conclusion (required section)

Current regulatory guidelines promote the use of risk based quality monitoring (RBQM) in clinical trials to support traditional onsite monitoring and medical review and data management. Most clinical trial data consist of repeated measurements taken of the same patients repetitavel over the duration of the trial. The integrity of these data points is mostly challenged by systemic errors introduced at site level which can have root causes such as: misinterpretation of the protocol, miscalibration of laboratory tests, inussficient staff training and many more. These errors will affect a larger portion of patients enrolled at the site and should be statistically detectable as site-level anomalies given that sufficient compliant data has been collected within the current trial data set. Classical risk mitigation strategies consist of a combination of monitoring activities such as source data verification (SDV) and source date review (SDR), programmed data management edit checks and medical data review. These activities are laboreous and ressource intensive and never cover the entire clinical data set. A risk- based framework targets these activities towards high risk areas such as critical data fields (e.g. clinical endpoints and safety data) and statistical outliers possibly indicating systemic site issues.

We have demonstrated that the ctas algorithm can be used to detect site-level anomalies of various kinds and that it gets more accurrate the more extreme the anomalies are. Within an RBQM framework ctas can be used to screen a clinical data set for site anomalies and target those for manual data review. The higher the score the more likely a site is to represent a genuine outlier that can be confirmed in a time series data visualisation. As the algorithm can cover the entire clinical data set, complete blind spots in the risk mitigation strategy can be avoided. Possible unforeseen scenarios missed by first line control activities (programmed edit check) can be detected.

Even though we have only tested ctas for the detection of anomolous sites for numerical time series data in this work, the statistics can also be used to detect patient-level outliers using the ctas statistics to create similarity plots. Further categorical variables can be transformed into a binary numerical representation and included in the outlier detection. Presently ctas requires multiple data preprocessing steps as well as a post reporting pipeline. Future development of ctas might provide a framework for those steps as well.



> The conclusions section should highlight the main conclusion(s), stating the answer to the study objective. The Conclusions section should be a distinct section.

# Funding statements (required section)

> The Funding section is mandatory. Authors must declare sources of study funding including sponsorship (e.g. university, charity, commercial organization) and sources of material (e.g. novel drugs) not available commercially. See the Editorial Policy section for detailed information and requirements on this section. This section should also include, if desired, special thanks or dedications. Work done by a contributor or medical writer that does not qualify him/her for authorship, but which warrants acknowledgement, should be noted here.

# Author Contributions (required section)

> A statement outlining each author's contributions is mandatory. In order to meet requirements of authorship, each author must have contributed to at least one of the aspects below. The ICMJE and Therapeutic Innovation & Regulatory Science considers authorship to be based on the following four criteria:  Substantial contributions to the conception or design of the work; or the acquisition, analysis, or interpretation of data for the work; and  Drafting the work or revising it critically for important intellectual content; and  Final approval of the version to be published; and  Agreement to be accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved. Additional information can be found under "Authorship." As per ICMJE best practice, information provided in this section is the responsibility of the authors.

# Figure Legends

@fig-timeseries-def Simplified example of time series definition. Blue cells denote subjects with a measurement at a given time point. Two time series have been defined. TS1 includes subjects (S1-S3) which have finished the study while the second time series (TS2) focuses on the first four time points and includes also subjects S4-S6 in addition to those in the TS1. Remaining subjects have data for too few time points to be considered in either of the time series.

@fig-timeseries-feats Example of a time series with four time points and the features calculated from it. There is one feature which needs more explanation: site co-clustering - a measure of how similar the time series is to other subjects from the same site vs. subjects from all other sites. It is used to identify sites whose time series for a particular parameter are more similar to each other than could be expected by chance. In the extreme case, this could be indicative of sample splitting, i.e., a type of fraud where samples are collected from only one individual but assigned to several subjects. Figure 3 illustrates how co-clustering is calculated for a single time series.

@fig-co-clustering Calculating a site co-clustering feature for a time series. Spheres on the left represent individual time series (red = time series for which we are calculating the feature (query), pink = time series of other subjects from the same site, white = time series of subjects from other sites). First the time series are ranked based on their distance to the query. A ROC curve is calculated for the ranked time series and a Area Under Curve (AUC) is calculated for the curve. The AUC is then used as the co-clustering feature. A feature of value of 1 means that fellow subjects from the same site are all closer to the query than subjects from other sites. A value of zero is the opposite of this and the value 0.5 means that there is no difference between subjects from the query's own site and the subjects from other sites.

@fig-site-flagging Example of site flagging. The timeseries has eight time points and the question is whether the site (six subjects) has reported fewer unique values per time series than other sites in the study. Part 1) has the individual subject time series and the unique value counts. It is clear from the histograms (2) that the site is biased when compared to other sites. To quantify the bias, the distributions are compared with the Kolmogorov-Smirnov test (3) which gives us a raw p-value. As we perform several tests per study, the p-value must be corrected (4). Finally, the negative logarithm of the corrected p-value is taken to come up with the final score for the site (5).

@fig-co-cluster-example Example of co-clustering of systolic blood pressure profiles. Site X was flagged by the tool for a significant bias in the site co-clustering feature. This is evident in the time series (1) as almost all measurements are within the narrow range of 120 to 140 mmHg whereas measurements from other sites vary over a wider range (blue lines). This is also evident in the similarity plot (2) which visualizes the relative distance between time series. On this plot, almost all Site X subjects (filled circles) are clearly co-clustered.

@fig-average-example Example of a site with systematically large values for a laboratory assay. The difference in the average results is clear in both the histogram (1) and the individual time series (2).

@fig-similarity-plot An anomalous weight profile identified based on its distance from other profiles on the similarity plot (left). The profile is given on the right with a sudden drop in weight followed by a return to the previous values. In this case, the reason is probably a data entry error at site.

@fig-sd-example Identifying an individual time series outlier based on a time series feature. In this case the subject with most variable bilirubin profile (1) has been selected and highlighted with the other subjects (2). In this case, it is possible that the site has collected the data correctly but this might be interesting for someone performing medical review to identify safety issues, for example.


@fig-anomalies Simulated site-level anomalies of of varying degree across different anomaly types. Timelines from regular sites are shown in grey and timelines from an anomalous site in red. The number of patients per anomalous site is sampled from the distribution of the number of patients per site from the original data set. 

@fig-results True positive and false positive ratio across different simulation scenarios. Ratios are represented as the mean with standard deviation obtained by 15 replicates obtained from simulations based on different studies. Timelines from two laboratory (Alanine Aminotransferase, Creatinine) and 2 vitals mesurements (Systolic Blood Pressure, Weight) were selected to be included in the simulation. The simulations randomly introduced 3 anomalous sites with increasing anomaly degrees into each iteration which needed to be detected by the ctas algorithm. Study-level ratios were based on simulations with 100 iterations.

# Tables

> These should be labeled sequentially as Table 1, Table 2, etc. Each table should be typed on a separate page, numbered and titled, and cited in the text. Reference to table footnotes should be made by means of Arabic numerals. Tables should not duplicate the content of the text. They should consist of at least two columns; columns should always have headings. Authors should ensure that the data in the tables are consistent with those cited in the relevant places in the text, totals add up correctly, and percentages have been calculated correctly. Tables may be either included in the article file itself, but at the end of the manuscript, or supplied as separate files.

# Figures

![Timeseries Definition](timeseries_def.png){#fig-timeseries-def}

![Timeseries Features](timeseries_feats.png){#fig-timeseries-feats}

![Co-Clustering](co_clustering.png){#fig-co-clustering}

![Site Flagging](site_flagging.png){#fig-site-flagging}

![Example Co-Clustering](co_cluster_example.png){#fig-co-cluster-example}

![Example Average](average_example.png){#fig-average-example}

![Similarity Plot](similarity_plot.png){#fig-similarity-plot}

![Example Standard Deviation](sd_example.png){#fig-sd-example}

```{r echo=FALSE, fig.width=10, fig.height=9}
#| label: fig-anomalies
#| fig-cap: "Anomalies"

set.seed(1)
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(ctasval))

df_prep <- prep_sdtm_lb(pharmaversesdtm::lb, pharmaversesdtm::dm, scramble = TRUE)

df_filt <- df_prep %>%
  filter(parameter_id == "Alkaline Phosphatase")

set.seed(1)

df_anomaly <- tibble(
    anomaly_fun = list(
      anomaly_autocorr,
      anomaly_average,
      anomaly_lof,
      anomaly_range,
      anomaly_sd,
      anomaly_unique_value_count_relative
    ),
    anomaly = c(
      "autocorr",
      "average",
      "lof",
      "range",
      "sd",
      "unique_value_count_relative"
    )
  ) %>%
  mutate(
    anomaly_degree = list(c(0.25, 0.5, 0.75, 1, 5, 10))
  ) %>%
  unnest(anomaly_degree) %>%
  mutate(
    data = map2(anomaly_fun, anomaly_degree, ~ .x(df_filt, .y))
  ) %>%
  unnest(data)

ggplot(df_filt, aes(x = timepoint_rank, y = result, group = subject_id)) +
  geom_line(color = "darkgrey", alpha = 0.5) +
  geom_line(data = df_anomaly, color = "tomato", alpha = 0.5) +
  facet_grid(anomaly ~ anomaly_degree, scales = "free_y") +
  coord_cartesian(xlim = c(0, 15)) +
  theme_ctas() +
  labs(x = "Timepoint Rank", y = "Alkaline Phosphatase U/L")
  

```

```{r echo=FALSE, fig.height=12, fig.width=10}
#| label: fig-results
#| fig-cap: 
#|   - "Results"

path <- here::here("inst/pub/")

df_results <- tibble(
    files = dir(path, pattern = "collected_results_", full.names = TRUE)
  ) %>%
  mutate(
    data = purrr::map(files, ~ readr::read_csv(., show_col_types = FALSE))
  ) %>%
  unnest(data)

stopifnot(nrow(df_results) > 0)

plot_ratio <- function(df_results, ratio) {
  
  df_results %>%
    mutate(
      ratio = .data[[ratio]],
      ratio = replace_na(ratio, 0),
    ) %>%
    summarise(
      ratio_mean = mean(ratio),
      ratio_lwr = ratio_mean - sd(ratio),
      ratio_lwr = ifelse(ratio_lwr < 0, 0, ratio_lwr),
      ratio_upr = ratio_mean + sd(ratio),
      ratio_upr = ifelse(ratio_upr > 1, 1, ratio_upr),
      .by = c(parameter_id, feats, anomaly_degree, method)
    ) %>%
    ggplot(aes(log(anomaly_degree),  ratio_mean, color = method)) +
    geom_line(aes(color = method), alpha = 0.5) +
    geom_pointrange(aes(ymin = ratio_lwr, ymax = ratio_upr), alpha = 0.5) +
    facet_grid(parameter_id ~ feats) + 
    theme_ctas() +
    theme(legend.position = "bottom")
  
}

p_tpr <- plot_ratio(df_results, ratio = "tpr") +
  labs(
    y = "Average True Positive Ratio (+/- SD)",
    x = "Log Anomaly Degree",
    color = "Site Scoring Method"
  )


p_fpr <- plot_ratio(df_results, ratio = "fpr") +
  labs(
    y = "Average False Positive Ratio (+/- SD)",
    x = "Log Anomaly Degree",
    color = "Site Scoring Method"
  )

p_tpr / p_fpr / guide_area() + plot_layout(guides = "collect", axes = "collect", heights = c(1, 1, 0.1))
```

# References

::: {#refs}
:::


# Supporting Material


