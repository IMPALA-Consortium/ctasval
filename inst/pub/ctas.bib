
@article{benjamini_hochberg_1995,
	title = {Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing},
	volume = {57},
	issn = {1467-9868},
	url = {https://doi.org/10.1111/j.2517-6161.1995.tb02031.x},
	doi = {10.1111/j.2517-6161.1995.tb02031.x},
	language = {en},
	number = {1},
	urldate = {2025-02-18},
	journal = {J. R. Stat. Soc. Ser. B Methodol.},
	author = {Benjamini Y., Hochberg Y.},
	month = jan,
	year = {1995},
	keywords = {bonferroni-type procedures, familywise error rate, multiple-comparison procedures, p-values},
	pages = {289--300},
}

@article{blazquez-garcia_review_2021,
	title = {A {Review} on {Outlier}/{Anomaly} {Detection} in {Time} {Series} {Data}},
	volume = {54},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3444690},
	doi = {10.1145/3444690},
	abstract = {Recent advances in technology have brought major breakthroughs in data collection, enabling a large amount of data to be gathered over time and thus generating time series. Mining this data has become an important task for researchers and practitioners in the past few years, including the detection of outliers or anomalies that may represent errors or events of interest. This review aims to provide a structured and comprehensive state-of-the-art on unsupervised outlier detection techniques in the context of time series. To this end, a taxonomy is presented based on the main aspects that characterize an outlier detection technique.},
	number = {3},
	urldate = {2025-01-03},
	journal = {ACM Comput. Surv.},
	author = {Blázquez-García, Ane and Conde, Angel and Mori, Usue and Lozano, Jose A.},
	month = apr,
	year = {2021},
	pages = {56:1--56:33},
}

@article{kirkwood_application_2013,
	title = {Application of methods for central statistical monitoring in clinical trials},
	volume = {10},
	issn = {1740-7745},
	url = {https://doi.org/10.1177/1740774513494504},
	doi = {10.1177/1740774513494504},
	abstract = {BackgroundOn-site source data verification is a common and expensive activity, with little evidence that it is worthwhile. Central statistical monitoring (CSM) is a cheaper alternative, where data checks are performed by the coordinating centre, avoiding the need to visit all sites. Several publications have suggested methods for CSM; however, few have described their use in real trials.MethodsR-programs were created to check data at either the subject level (7 tests within 3 programs) or site level (9 tests within 8 programs) using previously described methods or new ones we developed. These aimed to find possible data errors such as outliers, incorrect dates, or anomalous data patterns; digit preference, values too close or too far from the means, unusual correlation structures, extreme variances which may indicate fraud or procedural errors and under-reporting of adverse events. The methods were applied to three trials, one of which had closed and has been published, one in follow-up, and a third to which fabricated data were added. We examined how well the methods work, discussing their strengths and limitations.ResultsThe R-programs produced simple tables or easy-to-read figures. Few data errors were found in the first two trials, and those added to the third were easily detected. The programs were able to identify patients with outliers based on single or multiple variables. They also detected (1) fabricated patients, generated to have values too close to the multivariate mean, or with too low variances in repeated measurements, and (2) sites which had unusual correlation structures or too few adverse events. Some methods were unreliable if applied to centres with few patients or if data were fabricated in a way which did not fit the assumptions used to create the programs. Outputs from the R-programs are interpreted using examples.LimitationsDetecting data errors is relatively straightforward; however, there are several limitations in the detection of fraud: some programs cannot be applied to small trials or to centres with few patients ({\textless}10) and data falsified in a manner which does not fit the program’s assumptions may not be detected. In addition, many tests require a visual assessment of the output (showing flagged participants or sites), before data queries are made or on-site visits performed.ConclusionsCSM is a worthwhile alternative to on-site data checking and may be used to limit the number of site visits by targeting only sites which are picked up by the programs. We summarise the methods, show how they are implemented and that they can be easy to interpret. The methods can identify incorrect or unusual data for a trial subject, or centres where the data considered together are too different to other centres and therefore should be reviewed, possibly through an on-site visit.},
	language = {en},
	number = {5},
	urldate = {2025-01-03},
	journal = {Clinical Trials},
	author = {Kirkwood, Amy A and Cox, Trevor and Hackshaw, Allan},
	month = oct,
	year = {2013},
	note = {Publisher: SAGE Publications},
	pages = {783--806},
}

@article{de_viron_does_2024,
	title = {Does {Central} {Statistical} {Monitoring} {Improve} {Data} {Quality}? {An} {Analysis} of 1,111 {Sites} in 159 {Clinical} {Trials}},
	volume = {58},
	issn = {2168-4804},
	shorttitle = {Does {Central} {Statistical} {Monitoring} {Improve} {Data} {Quality}?},
	url = {https://doi.org/10.1007/s43441-024-00613-w},
	doi = {10.1007/s43441-024-00613-w},
	abstract = {Central monitoring aims at improving the quality of clinical research by pro-actively identifying risks and remediating emerging issues in the conduct of a clinical trial that may have an adverse impact on patient safety and/or the reliability of trial results. This paper, focusing on statistical data monitoring (SDM), is the second of a series that attempts to quantify the impact of central monitoring in clinical trials.},
	language = {en},
	number = {3},
	urldate = {2025-01-03},
	journal = {Ther Innov Regul Sci},
	author = {de Viron, Sylviane and Trotta, Laura and Steijn, William and Young, Steve and Buyse, Marc},
	month = may,
	year = {2024},
	keywords = {Central monitoring, Clinical trial quality, Data quality assessment, RBM, RBQM, Risk-based monitoring, Risk-based quality management, Site performance, Statistical monitoring},
	pages = {483--494},
	file = {Full Text:/Users/koneswab/Zotero/storage/JKP9UVX5/de Viron et al. - 2024 - Does Central Statistical Monitoring Improve Data Q.pdf:application/pdf},
}

@article{venet_statistical_2012,
	title = {A statistical approach to central monitoring of data quality in clinical trials},
	volume = {9},
	issn = {1740-7745},
	url = {https://doi.org/10.1177/1740774512447898},
	doi = {10.1177/1740774512447898},
	abstract = {BackgroundClassical monitoring approaches rely on extensive on-site visits and source data verification. These activities are associated with high cost and a limited contribution to data quality. Central statistical monitoring is of particular interest to address these shortcomings.PurposeThis article outlines the principles of central statistical monitoring and the challenges of implementing it in actual trials.MethodsA statistical approach to central monitoring is based on a large number of statistical tests performed on all variables collected in the database, in order to identify centers that differ from the others. The tests generate a high-dimensional matrix of p-values, which can be analyzed by statistical methods and bioinformatic tools to identify extreme centers.ResultsResults from actual trials are provided to illustrate typical findings that can be expected from a central statistical monitoring approach, which detects abnormal patterns that were not (or could not have been) detected by on-site monitoring.LimitationsCentral statistical monitoring can only address problems present in the data. Important aspects of trial conduct such as a lack of informed consent documentation, for instance, require other approaches. The results provided here are empirical examples from a limited number of studies.ConclusionCentral statistical monitoring can both optimize on-site monitoring and improve data quality and as such provides a cost-effective way of meeting regulatory requirements for clinical trials.},
	language = {en},
	number = {6},
	urldate = {2025-01-03},
	journal = {Clinical Trials},
	author = {Venet, David and Doffagne, Erik and Burzykowski, Tomasz and Beckers, François and Tellier, Yves and Genevois-Marlin, Eric and Becker, Ursula and Bee, Valerie and Wilson, Veronique and Legrand, Catherine and Buyse, Marc},
	month = dec,
	year = {2012},
	note = {Publisher: SAGE Publications},
	pages = {705--713},
}

@article{desmet_linear_2014,
	title = {Linear mixed-effects models for central statistical monitoring of multicenter clinical trials},
	volume = {33},
	copyright = {Copyright © 2014 John Wiley \& Sons, Ltd.},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6294},
	doi = {10.1002/sim.6294},
	abstract = {Multicenter studies are widely used to meet accrual targets in clinical trials. Clinical data monitoring is required to ensure the quality and validity of the data gathered across centers. One approach to this end is central statistical monitoring, which aims at detecting atypical patterns in the data by means of statistical methods. In this context, we consider the simple case of a continuous variable, and we propose a detection procedure based on a linear mixed-effects model to detect location differences between each center and all other centers. We describe the performance of the procedure as a function of contamination rate and signal-to-noise ratio. We investigate the effect of center size and variance structure and illustrate the use of the procedure using data from two multicenter clinical trials. Copyright © 2014 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {30},
	urldate = {2025-01-03},
	journal = {Statistics in Medicine},
	author = {Desmet, L. and Venet, D. and Doffagne, E. and Timmermans, C. and Burzykowski, T. and Legrand, C. and Buyse, M.},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.6294},
	keywords = {statistical monitoring, contamination rate, error detection, linear mixed-effects model, multicenter clinical trial, signal-to-noise ratio},
	pages = {5265--5279},
	file = {Snapshot:/Users/koneswab/Zotero/storage/7S9A4224/sim.html:text/html},
}

@article{wu_good_2024,
	title = {Good {Statistical} {Monitoring}: {A} {Flexible} {Open}-{Source} {Tool} to {Detect} {Risks} in {Clinical} {Trials}},
	volume = {58},
	issn = {2168-4804},
	shorttitle = {Good {Statistical} {Monitoring}},
	url = {https://doi.org/10.1007/s43441-024-00651-4},
	doi = {10.1007/s43441-024-00651-4},
	abstract = {Risk-based quality management is a regulatory-recommended approach to manage risk in a clinical trial. A key element of this strategy is to conduct risk-based monitoring to detect potential risks to critical data and processes earlier. However, there are limited publicly available tools to perform the analytics required for this purpose. Good Statistical Monitoring is a new open-source solution developed to help address this need.},
	language = {en},
	number = {5},
	urldate = {2025-01-03},
	journal = {Ther Innov Regul Sci},
	author = {Wu, George and Childress, Spencer and Wang, Zhongkai and Roumaya, Matt and Stern, Colleen McLaughlin and Dickens, Chelsea and Wildfire, Jeremy},
	month = sep,
	year = {2024},
	keywords = {Risk-based monitoring, Risk-based quality management, Statistical monitoring, Interactive graphics, R},
	pages = {838--844},
}

@misc{noauthor_ich_1997,
	title = {{ICH} {E6} ({R2}) {Good} clinical practice - {Scientific} guideline {\textbar} {European} {Medicines} {Agency} ({EMA})},
	url = {https://www.ema.europa.eu/en/ich-e6-r2-good-clinical-practice-scientific-guideline},
	abstract = {This guideline addresses the good clinical practice, an international ethical and scientific quality standard for designing, conducting, recording and reporting trials that involve the participation of human subjects. It aims to provide a unified standard for the ICH regions to facilitate the mutual acceptance of clinical data by the regulatory authorities in these jurisdictions.},
	language = {en},
	urldate = {2025-01-03},
	month = jan,
	year = {1997},
	file = {Snapshot:/Users/koneswab/Zotero/storage/3BUMWS2U/ich-e6-r2-good-clinical-practice-scientific-guideline.html:text/html},
}

@article{trotta_detection_2019,
	title = {Detection of atypical data in multicenter clinical trials using unsupervised statistical monitoring},
	volume = {16},
	issn = {1740-7745},
	url = {https://doi.org/10.1177/1740774519862564},
	doi = {10.1177/1740774519862564},
	abstract = {Background/AimsA risk-based approach to clinical research may include a central statistical assessment of data quality. We investigated the operating characteristics of unsupervised statistical monitoring aimed at detecting atypical data in multicenter experiments. The approach is premised on the assumption that, save for random fluctuations and natural variations, data coming from all centers should be comparable and statistically consistent. Unsupervised statistical monitoring consists of performing as many statistical tests as possible on all trial data, in order to detect centers whose data are inconsistent with data from other centers.MethodsWe conducted simulations using data from a large multicenter trial conducted in Japan for patients with advanced gastric cancer. The actual trial data were contaminated in computer simulations for varying percentages of centers, percentages of patients modified within each center and numbers and types of modified variables. The unsupervised statistical monitoring software was run by a blinded team on the contaminated data sets, with the purpose of detecting the centers with contaminated data. The operating characteristics (sensitivity, specificity and Youden’s J-index) were calculated for three detection methods: one using the p-values of individual statistical tests after adjustment for multiplicity, one using a summary of all p-values for a given center, called the Data Inconsistency Score, and one using both of these methods.ResultsThe operating characteristics of the three methods were satisfactory in situations of data contamination likely to occur in practice, specifically when a single or a few centers were contaminated. As expected, the sensitivity increased for increasing proportions of patients and increasing numbers of variables contaminated. The three methods showed a specificity better than 93\% in all scenarios of contamination. The method based on the Data Inconsistency Score and individual p-values adjusted for multiplicity generally had slightly higher sensitivity at the expense of a slightly lower specificity.ConclusionsThe use of brute force (a computer-intensive approach that generates large numbers of statistical tests) is an effective way to check data quality in multicenter clinical trials. It can provide a cost-effective complement to other data-management and monitoring techniques.},
	language = {en},
	number = {5},
	urldate = {2025-01-03},
	journal = {Clinical Trials},
	author = {Trotta, Laura and Kabeya, Yuusuke and Buyse, Marc and Doffagne, Erik and Venet, David and Desmet, Lieven and Burzykowski, Tomasz and Tsuburaya, Akira and Yoshida, Kazuhiro and Miyashita, Yumi and Morita, Satoshi and Sakamoto, Junichi and Praveen, Paurush and Oba, Koji},
	month = oct,
	year = {2019},
	note = {Publisher: SAGE Publications},
	pages = {512--522},
}

@article{breunig_lof_2000,
	title = {{LOF}: identifying density-based local outliers},
	volume = {29},
	issn = {0163-5808},
	shorttitle = {{LOF}},
	url = {https://dl.acm.org/doi/10.1145/335191.335388},
	doi = {10.1145/335191.335388},
	abstract = {For many KDD applications, such as detecting criminal activities in E-commerce, finding the rare instances or the outliers, can be more interesting than finding the common patterns. Existing work in outlier detection regards being an outlier as a binary property. In this paper, we contend that for many scenarios, it is more meaningful to assign to each object a degree of being an outlier. This degree is called the local outlier factor (LOF) of an object. It is local in that the degree depends on how isolated the object is with respect to the surrounding neighborhood. We give a detailed formal analysis showing that LOF enjoys many desirable properties. Using real-world datasets, we demonstrate that LOF can be used to find outliers which appear to be meaningful, but can otherwise not be identified with existing approaches. Finally, a careful performance evaluation of our algorithm confirms we show that our approach of finding local outliers can be practical.},
	number = {2},
	urldate = {2025-01-20},
	journal = {SIGMOD Rec.},
	author = {Breunig, Markus M. and Kriegel, Hans-Peter and Ng, Raymond T. and Sander, Jörg},
	month = may,
	year = {2000},
	pages = {93--104},
}

@article{hodges_significance_1958,
	title = {The significance probability of the smirnov two-sample test},
	volume = {3},
	issn = {1871-2487},
	url = {https://doi.org/10.1007/BF02589501},
	doi = {10.1007/BF02589501},
	language = {en},
	number = {5},
	urldate = {2025-01-20},
	journal = {Ark. Mat.},
	author = {Hodges, J. L.},
	month = jan,
	year = {1958},
	keywords = {Continuity Correction, Empirical Distribution, Heuristic Argument, Kolmogorov Test, Notational Complication},
	pages = {469--486},
}

@article{schroer_exact_1995,
	title = {Exact and randomization distributions of {Kolmogorov}-{Smirnov} tests two or three samples},
	volume = {20},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/016794739400040P},
	doi = {10.1016/0167-9473(94)00040-P},
	abstract = {The aim of this paper is to compare several test procedures for the two- or three-sample case. These comprise the Birnbaum-Hall test and the k-sample Smirnov test as described in Conover (1980), for instance. To compute the exact distributions of these test statistics, an algorithm developed by Hodges (1957) is extended in two ways, namely, to cover the presence of ties and to generalize it to the three-sample case. This extension can be used to find the distributions of the Birnbaum-Hall and Smirnov test statistic when there are unequal sample sizes, which fills a gap in the literature. Furthermore, we propose a new test where the test statistic measures the area between empirical distribution functions. To make this procedure feasible, a randomized version is studied. The results of a simulation study are reported comparing the performances of several parametric and nonparametric tests. Especially the effects of location or dispersion alternatives are taken into account as well as the presence of ties and outliers.},
	number = {2},
	urldate = {2025-01-20},
	journal = {Computational Statistics \& Data Analysis},
	author = {Schröer, Gunar and Trenkler, Dietrich},
	month = aug,
	year = {1995},
	keywords = {-sample test, Critical values, Empirical distribution function, Kolmogorov-Smirnov tests, Randomization test, Sequential procedure},
	pages = {185--202},
	file = {ScienceDirect Snapshot:/Users/koneswab/Zotero/storage/5DI7ZGBH/016794739400040P.html:text/html},
}

@Manual{pharmaversesdtm,
  title = {pharmaversesdtm: SDTM Test Data for the 'Pharmaverse' Family of Packages},
  author = {Edoardo Mancini and Gayatri G and Kangjie Zhang and Pooja Kumari and Stefan Bundfuss and Zelos Zhu and Sadchla Mascary and Vladyslav Shuliar and Vinh Nguyen},
  year = {2025},
  note = {R package version 1.2.0, https://github.com/pharmaverse/pharmaversesdtm/},
  url = {https://pharmaverse.github.io/pharmaversesdtm/},
}
